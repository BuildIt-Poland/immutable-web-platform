apiVersion: v1
items:
- apiVersion: v1
  kind: Namespace
  metadata:
    labels:
      istio-injection: enabled
      kubenix/project-name: kubenix
    name: functions
    namespace: default
- apiVersion: v1
  kind: Namespace
  metadata:
    labels:
      kubenix/project-name: kubenix
    name: istio-system
    namespace: default
- apiVersion: networking.istio.io/v1alpha3
  kind: DestinationRule
  metadata:
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-telemetry
    namespace: istio-system
  spec:
    host: istio-telemetry.istio-system.svc.cluster.local
    trafficPolicy:
      connectionPool:
        http:
          http2MaxRequests: 10000
          maxRequestsPerConnection: 10000
- apiVersion: networking.istio.io/v1alpha3
  kind: Gateway
  metadata:
    labels:
      kubenix/project-name: kubenix
    name: virtual-services-gateway
    namespace: default
  spec:
    selector:
      istio: virtual-services-gateway
    servers:
    - hosts:
      - '*'
      port:
        name: http-weavescope
        number: 15301
        protocol: HTTP
    - hosts:
      - '*'
      port:
        name: http-grafana
        number: 15300
        protocol: HTTP
    - hosts:
      - '*'
      port:
        name: http-zipkin
        number: 15302
        protocol: HTTP
    - hosts:
      - '*'
      port:
        name: http2-argocd
        number: 15200
        protocol: HTTPS
      tls:
        mode: PASSTHROUGH
- apiVersion: networking.istio.io/v1alpha3
  kind: VirtualService
  metadata:
    labels:
      kubenix/project-name: kubenix
    name: virtual-service
    namespace: default
  spec:
    gateways:
    - virtual-services-gateway
    hosts:
    - '*'
    http:
    - match:
      - port: 15300
      route:
      - destination:
          host: grafana.knative-monitoring.svc.cluster.local
          port:
            number: 30802
    - match:
      - port: 15301
      route:
      - destination:
          host: weave-scope-app.istio-system.svc.cluster.local
          port:
            number: 80
    - match:
      - port: 15302
      route:
      - destination:
          host: zipkin.istio-system.svc.cluster.local
          port:
            number: 9411
    tls:
    - match:
      - port: 15200
        sni_hosts:
        - localhost
        - kind.local
        - '*'
      route:
      - destination:
          host: argocd-server.argocd.svc.cluster.local
          port:
            number: 443
- apiVersion: config.istio.io/v1alpha2
  kind: attributemanifest
  metadata:
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istioproxy
    namespace: istio-system
  spec:
    attributes:
      api.operation:
        valueType: STRING
      api.protocol:
        valueType: STRING
      api.service:
        valueType: STRING
      api.version:
        valueType: STRING
      check.cache_hit:
        valueType: BOOL
      check.error_code:
        valueType: INT64
      check.error_message:
        valueType: STRING
      connection.duration:
        valueType: DURATION
      connection.event:
        valueType: STRING
      connection.id:
        valueType: STRING
      connection.mtls:
        valueType: BOOL
      connection.received.bytes:
        valueType: INT64
      connection.received.bytes_total:
        valueType: INT64
      connection.requested_server_name:
        valueType: STRING
      connection.sent.bytes:
        valueType: INT64
      connection.sent.bytes_total:
        valueType: INT64
      context.protocol:
        valueType: STRING
      context.proxy_error_code:
        valueType: STRING
      context.reporter.kind:
        valueType: STRING
      context.reporter.local:
        valueType: BOOL
      context.reporter.uid:
        valueType: STRING
      context.time:
        valueType: TIMESTAMP
      context.timestamp:
        valueType: TIMESTAMP
      destination.port:
        valueType: INT64
      destination.principal:
        valueType: STRING
      destination.uid:
        valueType: STRING
      origin.ip:
        valueType: IP_ADDRESS
      origin.uid:
        valueType: STRING
      origin.user:
        valueType: STRING
      quota.cache_hit:
        valueType: BOOL
      rbac.permissive.effective_policy_id:
        valueType: STRING
      rbac.permissive.response_code:
        valueType: STRING
      request.api_key:
        valueType: STRING
      request.auth.audiences:
        valueType: STRING
      request.auth.claims:
        valueType: STRING_MAP
      request.auth.presenter:
        valueType: STRING
      request.auth.principal:
        valueType: STRING
      request.auth.raw_claims:
        valueType: STRING
      request.headers:
        valueType: STRING_MAP
      request.host:
        valueType: STRING
      request.id:
        valueType: STRING
      request.method:
        valueType: STRING
      request.path:
        valueType: STRING
      request.query_params:
        valueType: STRING_MAP
      request.reason:
        valueType: STRING
      request.referer:
        valueType: STRING
      request.scheme:
        valueType: STRING
      request.size:
        valueType: INT64
      request.time:
        valueType: TIMESTAMP
      request.total_size:
        valueType: INT64
      request.url_path:
        valueType: STRING
      request.useragent:
        valueType: STRING
      response.code:
        valueType: INT64
      response.duration:
        valueType: DURATION
      response.grpc_message:
        valueType: STRING
      response.grpc_status:
        valueType: STRING
      response.headers:
        valueType: STRING_MAP
      response.size:
        valueType: INT64
      response.time:
        valueType: TIMESTAMP
      response.total_size:
        valueType: INT64
      source.principal:
        valueType: STRING
      source.uid:
        valueType: STRING
      source.user:
        valueType: STRING
- apiVersion: config.istio.io/v1alpha2
  kind: attributemanifest
  metadata:
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: kubernetes
    namespace: istio-system
  spec:
    attributes:
      destination.container.name:
        valueType: STRING
      destination.ip:
        valueType: IP_ADDRESS
      destination.labels:
        valueType: STRING_MAP
      destination.metadata:
        valueType: STRING_MAP
      destination.name:
        valueType: STRING
      destination.namespace:
        valueType: STRING
      destination.owner:
        valueType: STRING
      destination.service.host:
        valueType: STRING
      destination.service.name:
        valueType: STRING
      destination.service.namespace:
        valueType: STRING
      destination.service.uid:
        valueType: STRING
      destination.serviceAccount:
        valueType: STRING
      destination.workload.name:
        valueType: STRING
      destination.workload.namespace:
        valueType: STRING
      destination.workload.uid:
        valueType: STRING
      source.ip:
        valueType: IP_ADDRESS
      source.labels:
        valueType: STRING_MAP
      source.metadata:
        valueType: STRING_MAP
      source.name:
        valueType: STRING
      source.namespace:
        valueType: STRING
      source.owner:
        valueType: STRING
      source.serviceAccount:
        valueType: STRING
      source.services:
        valueType: STRING
      source.workload.name:
        valueType: STRING
      source.workload.namespace:
        valueType: STRING
      source.workload.uid:
        valueType: STRING
- apiVersion: config.istio.io/v1alpha2
  kind: kubernetes
  metadata:
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: attributes
    namespace: istio-system
  spec:
    attribute_bindings:
      destination.container.name: $out.destination_container_name | "unknown"
      destination.ip: $out.destination_pod_ip | ip("0.0.0.0")
      destination.labels: $out.destination_labels | emptyStringMap()
      destination.name: $out.destination_pod_name | "unknown"
      destination.namespace: $out.destination_namespace | "default"
      destination.owner: $out.destination_owner | "unknown"
      destination.serviceAccount: $out.destination_service_account_name | "unknown"
      destination.uid: $out.destination_pod_uid | "unknown"
      destination.workload.name: $out.destination_workload_name | "unknown"
      destination.workload.namespace: $out.destination_workload_namespace | "unknown"
      destination.workload.uid: $out.destination_workload_uid | "unknown"
      source.ip: $out.source_pod_ip | ip("0.0.0.0")
      source.labels: $out.source_labels | emptyStringMap()
      source.name: $out.source_pod_name | "unknown"
      source.namespace: $out.source_namespace | "default"
      source.owner: $out.source_owner | "unknown"
      source.serviceAccount: $out.source_service_account_name | "unknown"
      source.uid: $out.source_pod_uid | "unknown"
      source.workload.name: $out.source_workload_name | "unknown"
      source.workload.namespace: $out.source_workload_namespace | "unknown"
      source.workload.uid: $out.source_workload_uid | "unknown"
    destination_port: destination.port | 0
    destination_uid: destination.uid | ""
    source_ip: source.ip | ip("0.0.0.0")
    source_uid: source.uid | ""
- apiVersion: config.istio.io/v1alpha2
  kind: rule
  metadata:
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: kubeattrgenrulerule
    namespace: istio-system
  spec:
    actions:
    - handler: kubernetesenv
      instances:
      - attributes.kubernetes
- apiVersion: config.istio.io/v1alpha2
  kind: rule
  metadata:
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: tcpkubeattrgenrulerule
    namespace: istio-system
  spec:
    actions:
    - handler: kubernetesenv
      instances:
      - attributes.kubernetes
    match: context.protocol == "tcp"
- apiVersion: config.istio.io/v1alpha2
  kind: handler
  metadata:
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: kubernetesenv
    namespace: istio-system
  spec:
    compiledAdapter: kubernetesenv
- apiVersion: admissionregistration.k8s.io/v1beta1
  kind: MutatingWebhookConfiguration
  metadata:
    labels:
      app: sidecarInjectorWebhook
      chart: sidecarInjectorWebhook
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-sidecar-injector
    namespace: istio-system
  webhooks:
  - clientConfig:
      caBundle: ''
      service:
        name: istio-sidecar-injector
        namespace: istio-system
        path: /inject
    failurePolicy: Fail
    name: sidecar-injector.istio.io
    namespaceSelector:
      matchLabels:
        istio-injection: enabled
    rules:
    - apiGroups:
      - ''
      apiVersions:
      - v1
      operations:
      - CREATE
      resources:
      - pods
- apiVersion: autoscaling/v2beta1
  kind: HorizontalPodAutoscaler
  metadata:
    labels:
      app: ingressgateway
      chart: gateways
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-ingressgateway
    namespace: istio-system
  spec:
    maxReplicas: 1
    metrics:
    - resource:
        name: cpu
        targetAverageUtilization: 80
      type: Resource
    minReplicas: 1
    scaleTargetRef:
      apiVersion: apps/v1beta1
      kind: Deployment
      name: istio-ingressgateway
- apiVersion: autoscaling/v2beta1
  kind: HorizontalPodAutoscaler
  metadata:
    labels:
      app: pilot
      chart: pilot
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-pilot
    namespace: istio-system
  spec:
    maxReplicas: 5
    metrics:
    - resource:
        name: cpu
        targetAverageUtilization: 80
      type: Resource
    minReplicas: 2
    scaleTargetRef:
      apiVersion: apps/v1beta1
      kind: Deployment
      name: istio-pilot
- apiVersion: autoscaling/v2beta1
  kind: HorizontalPodAutoscaler
  metadata:
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-telemetry
    namespace: istio-system
  spec:
    maxReplicas: 5
    metrics:
    - resource:
        name: cpu
        targetAverageUtilization: 80
      type: Resource
    minReplicas: 1
    scaleTargetRef:
      apiVersion: apps/v1beta1
      kind: Deployment
      name: istio-telemetry
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      helm.sh/hook: post-delete
      helm.sh/hook-delete-policy: hook-succeeded
      helm.sh/hook-weight: '3'
    labels:
      app: security
      chart: security
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-cleanup-secrets-1.1.9
    namespace: istio-system
  spec:
    template:
      metadata:
        labels:
          app: security
          chart: security
          heritage: Tiller
          release: istio
        name: istio-cleanup-secrets
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - ppc64le
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - s390x
              weight: 2
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
                  - ppc64le
                  - s390x
        containers:
        - command:
          - /bin/bash
          - -c
          - "kubectl get secret --all-namespaces | grep \"istio.io/key-and-cert\"\
            \ |  while read -r entry; do\n  ns=$(echo $entry | awk '{print $1}');\n\
            \  name=$(echo $entry | awk '{print $2}');\n  kubectl delete secret $name\
            \ -n $ns;\ndone\n"
          image: docker.io/istio/kubectl:1.1.9
          imagePullPolicy: IfNotPresent
          name: kubectl
        restartPolicy: OnFailure
        serviceAccountName: istio-cleanup-secrets-service-account
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      helm.sh/hook: post-install
      helm.sh/hook-delete-policy: hook-succeeded
    labels:
      app: security
      chart: security
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-security-post-install-1.1.9
    namespace: istio-system
  spec:
    template:
      metadata:
        labels:
          app: security
          chart: security
          heritage: Tiller
          release: istio
        name: istio-security-post-install
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - ppc64le
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - s390x
              weight: 2
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
                  - ppc64le
                  - s390x
        containers:
        - command:
          - /bin/bash
          - /tmp/security/run.sh
          - /tmp/security/custom-resources.yaml
          image: docker.io/istio/kubectl:1.1.9
          imagePullPolicy: IfNotPresent
          name: kubectl
          volumeMounts:
          - mountPath: /tmp/security
            name: tmp-configmap-security
        restartPolicy: OnFailure
        serviceAccountName: istio-security-post-install-account
        volumes:
        - configMap:
            name: istio-security-custom-resources
          name: tmp-configmap-security
- apiVersion: v1
  data:
    mesh: "# Set the following variable to true to disable policy checks by the Mixer.\n\
      # Note that metrics will still be reported to the Mixer.\ndisablePolicyChecks:\
      \ true\n\n# Set enableTracing to false to disable request tracing.\nenableTracing:\
      \ true\n\n# Set accessLogFile to empty string to disable access log.\naccessLogFile:\
      \ \"\"\n\n# If accessLogEncoding is TEXT, value will be used directly as the\
      \ log format\n# example: \"[%START_TIME%] %REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)%\
      \ %PROTOCOL%\\n\"\n# If AccessLogEncoding is JSON, value will be parsed as map[string]string\n\
      # example: '{\"start_time\": \"%START_TIME%\", \"req_method\": \"%REQ(:METHOD)%\"\
      }'\n# Leave empty to use default log format\naccessLogFormat: \"\"\n\n# Set\
      \ accessLogEncoding to JSON or TEXT to configure sidecar access log\naccessLogEncoding:\
      \ 'TEXT'\nmixerReportServer: istio-telemetry.istio-system.svc.cluster.local:9091\n\
      # Let Pilot give ingresses the public IP of the Istio ingressgateway\ningressService:\
      \ istio-ingressgateway\n\n# Default connect timeout for dynamic clusters generated\
      \ by Pilot and returned via XDS\nconnectTimeout: 10s\n\n# DNS refresh rate for\
      \ Envoy clusters of type STRICT_DNS\ndnsRefreshRate: 5s\n\n# Unix Domain Socket\
      \ through which envoy communicates with NodeAgent SDS to get\n# key/cert for\
      \ mTLS. Use secret-mount files instead of SDS if set to empty. \nsdsUdsPath:\
      \ \n\n# This flag is used by secret discovery service(SDS). \n# If set to true(prerequisite:\
      \ https://kubernetes.io/docs/concepts/storage/volumes/#projected), Istio will\
      \ inject volumes mount \n# for k8s service account JWT, so that K8s API server\
      \ mounts k8s service account JWT to envoy container, which \n# will be used\
      \ to generate key/cert eventually. This isn't supported for non-k8s case.\n\
      enableSdsTokenMount: false\n\n# This flag is used by secret discovery service(SDS).\
      \ \n# If set to true, envoy will fetch normal k8s service account JWT from '/var/run/secrets/kubernetes.io/serviceaccount/token'\
      \ \n# (https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#accessing-the-api-from-a-pod)\
      \ \n# and pass to sds server, which will be used to request key/cert eventually.\
      \ \n# this flag is ignored if enableSdsTokenMount is set.\n# This isn't supported\
      \ for non-k8s case.\nsdsUseK8sSaJwt: false\n\n# The trust domain corresponds\
      \ to the trust root of a system.\n# Refer to https://github.com/spiffe/spiffe/blob/master/standards/SPIFFE-ID.md#21-trust-domain\n\
      trustDomain: \n\n# Set the default behavior of the sidecar for handling outbound\
      \ traffic from the application:\n# ALLOW_ANY - outbound traffic to unknown destinations\
      \ will be allowed, in case there are no\n#   services or ServiceEntries for\
      \ the destination port\n# REGISTRY_ONLY - restrict outbound traffic to services\
      \ defined in the service registry as well\n#   as those defined through ServiceEntries\
      \  \noutboundTrafficPolicy:\n  mode: ALLOW_ANY\n\nlocalityLbSetting:\n  {}\n\
      \  \n\n# The namespace to treat as the administrative root namespace for istio\n\
      # configuration.    \nrootNamespace: istio-system\nconfigSources:\n- address:\
      \ istio-galley.istio-system.svc:9901\n\ndefaultConfig:\n  #\n  # TCP connection\
      \ timeout between Envoy & the application, and between Envoys.  Used for static\
      \ clusters\n  # defined in Envoy's configuration file\n  connectTimeout: 10s\n\
      \  #\n  ### ADVANCED SETTINGS #############\n  # Where should envoy's configuration\
      \ be stored in the istio-proxy container\n  configPath: \"/etc/istio/proxy\"\
      \n  binaryPath: \"/usr/local/bin/envoy\"\n  # The pseudo service name used for\
      \ Envoy.\n  serviceCluster: istio-proxy\n  # These settings that determine how\
      \ long an old Envoy\n  # process should be kept alive after an occasional reload.\n\
      \  drainDuration: 45s\n  parentShutdownDuration: 1m0s\n  #\n  # The mode used\
      \ to redirect inbound connections to Envoy. This setting\n  # has no effect\
      \ on outbound traffic: iptables REDIRECT is always used for\n  # outbound connections.\n\
      \  # If \"REDIRECT\", use iptables REDIRECT to NAT and redirect to Envoy.\n\
      \  # The \"REDIRECT\" mode loses source addresses during redirection.\n  # If\
      \ \"TPROXY\", use iptables TPROXY to redirect to Envoy.\n  # The \"TPROXY\"\
      \ mode preserves both the source and destination IP\n  # addresses and ports,\
      \ so that they can be used for advanced filtering\n  # and manipulation.\n \
      \ # The \"TPROXY\" mode also configures the sidecar to run with the\n  # CAP_NET_ADMIN\
      \ capability, which is required to use TPROXY.\n  #interceptionMode: REDIRECT\n\
      \  #\n  # Port where Envoy listens (on local host) for admin commands\n  # You\
      \ can exec into the istio-proxy container in a pod and\n  # curl the admin port\
      \ (curl http://localhost:15000/) to obtain\n  # diagnostic information from\
      \ Envoy. See\n  # https://lyft.github.io/envoy/docs/operations/admin.html\n\
      \  # for more details\n  proxyAdminPort: 15000\n  #\n  # Set concurrency to\
      \ a specific number to control the number of Proxy worker threads.\n  # If set\
      \ to 0 (default), then start worker thread for each CPU thread/core.\n  concurrency:\
      \ 2\n  #\n  tracing:\n    zipkin:\n      # Address of the Zipkin collector\n\
      \      address: zipkin.istio-system:9411\n  #\n  # Mutual TLS authentication\
      \ between sidecars and istio control plane.\n  controlPlaneAuthPolicy: NONE\n\
      \  #\n  # Address where istio Pilot service is running\n  discoveryAddress:\
      \ istio-pilot.istio-system:15010"
    meshNetworks: 'networks: {}'
  kind: ConfigMap
  metadata:
    labels:
      app: istio
      chart: istio
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio
    namespace: istio-system
- apiVersion: v1
  data:
    validatingwebhookconfiguration.yaml: "apiVersion: admissionregistration.k8s.io/v1beta1\n\
      kind: ValidatingWebhookConfiguration\nmetadata:\n  name: istio-galley\n  namespace:\
      \ istio-system\n  labels:\n    app: galley\n    chart: galley\n    heritage:\
      \ Tiller\n    release: istio\n    istio: galley\nwebhooks:\n  - name: pilot.validation.istio.io\n\
      \    clientConfig:\n      service:\n        name: istio-galley\n        namespace:\
      \ istio-system\n        path: \"/admitpilot\"\n      caBundle: \"\"\n    rules:\n\
      \      - operations:\n        - CREATE\n        - UPDATE\n        apiGroups:\n\
      \        - config.istio.io\n        apiVersions:\n        - v1alpha2\n     \
      \   resources:\n        - httpapispecs\n        - httpapispecbindings\n    \
      \    - quotaspecs\n        - quotaspecbindings\n      - operations:\n      \
      \  - CREATE\n        - UPDATE\n        apiGroups:\n        - rbac.istio.io\n\
      \        apiVersions:\n        - \"*\"\n        resources:\n        - \"*\"\n\
      \      - operations:\n        - CREATE\n        - UPDATE\n        apiGroups:\n\
      \        - authentication.istio.io\n        apiVersions:\n        - \"*\"\n\
      \        resources:\n        - \"*\"\n      - operations:\n        - CREATE\n\
      \        - UPDATE\n        apiGroups:\n        - networking.istio.io\n     \
      \   apiVersions:\n        - \"*\"\n        resources:\n        - destinationrules\n\
      \        - envoyfilters\n        - gateways\n        - serviceentries\n    \
      \    - sidecars\n        - virtualservices\n    failurePolicy: Fail\n  - name:\
      \ mixer.validation.istio.io\n    clientConfig:\n      service:\n        name:\
      \ istio-galley\n        namespace: istio-system\n        path: \"/admitmixer\"\
      \n      caBundle: \"\"\n    rules:\n      - operations:\n        - CREATE\n\
      \        - UPDATE\n        apiGroups:\n        - config.istio.io\n        apiVersions:\n\
      \        - v1alpha2\n        resources:\n        - rules\n        - attributemanifests\n\
      \        - circonuses\n        - deniers\n        - fluentds\n        - kubernetesenvs\n\
      \        - listcheckers\n        - memquotas\n        - noops\n        - opas\n\
      \        - prometheuses\n        - rbacs\n        - solarwindses\n        -\
      \ stackdrivers\n        - cloudwatches\n        - dogstatsds\n        - statsds\n\
      \        - stdios\n        - apikeys\n        - authorizations\n        - checknothings\n\
      \        # - kuberneteses\n        - listentries\n        - logentries\n   \
      \     - metrics\n        - quotas\n        - reportnothings\n        - tracespans\n\
      \    failurePolicy: Fail"
  kind: ConfigMap
  metadata:
    labels:
      app: galley
      chart: galley
      heritage: Tiller
      istio: galley
      kubenix/project-name: kubenix
      release: istio
    name: istio-galley-configuration
    namespace: istio-system
- apiVersion: v1
  data:
    custom-resources.yaml: "# Authentication policy to enable permissive mode for\
      \ all services (that have sidecar) in the mesh.\napiVersion: \"authentication.istio.io/v1alpha1\"\
      \nkind: \"MeshPolicy\"\nmetadata:\n  name: \"default\"\n  labels:\n    app:\
      \ security\n    chart: security\n    heritage: Tiller\n    release: istio\n\
      spec:\n  peers:\n  - mtls:\n      mode: PERMISSIVE"
    run.sh: "#!/bin/sh\n\nset -x\n\nif [ \"$#\" -ne \"1\" ]; then\n    echo \"first\
      \ argument should be path to custom resource yaml\"\n    exit 1\nfi\n\npathToResourceYAML=${1}\n\
      \nkubectl get validatingwebhookconfiguration istio-galley 2>/dev/null\nif [\
      \ \"$?\" -eq 0 ]; then\n    echo \"istio-galley validatingwebhookconfiguration\
      \ found - waiting for istio-galley deployment to be ready\"\n    while true;\
      \ do\n        kubectl -n istio-system get deployment istio-galley 2>/dev/null\n\
      \        if [ \"$?\" -eq 0 ]; then\n            break\n        fi\n        sleep\
      \ 1\n    done\n    kubectl -n istio-system rollout status deployment istio-galley\n\
      \    if [ \"$?\" -ne 0 ]; then\n        echo \"istio-galley deployment rollout\
      \ status check failed\"\n        exit 1\n    fi\n    echo \"istio-galley deployment\
      \ ready for configuration validation\"\nfi\nsleep 5\nkubectl apply -f ${pathToResourceYAML}"
  kind: ConfigMap
  metadata:
    labels:
      app: security
      chart: security
      heritage: Tiller
      istio: citadel
      kubenix/project-name: kubenix
      release: istio
    name: istio-security-custom-resources
    namespace: istio-system
- apiVersion: v1
  data:
    config: "policy: disabled\ntemplate: |-\n  rewriteAppHTTPProbe: false\n  initContainers:\n\
      \  [[ if ne (annotation .ObjectMeta `sidecar.istio.io/interceptionMode` .ProxyConfig.InterceptionMode)\
      \ \"NONE\" ]]\n  - name: istio-init\n    image: \"docker.io/istio/proxy_init:1.1.9\"\
      \n    args:\n    - \"-p\"\n    - [[ .MeshConfig.ProxyListenPort ]]\n    - \"\
      -u\"\n    - 1337\n    - \"-m\"\n    - [[ annotation .ObjectMeta `sidecar.istio.io/interceptionMode`\
      \ .ProxyConfig.InterceptionMode ]]\n    - \"-i\"\n    - \"[[ annotation .ObjectMeta\
      \ `traffic.sidecar.istio.io/includeOutboundIPRanges`  \"*\"  ]]\"\n    - \"\
      -x\"\n    - \"[[ annotation .ObjectMeta `traffic.sidecar.istio.io/excludeOutboundIPRanges`\
      \  \"\"  ]]\"\n    - \"-b\"\n    - \"[[ annotation .ObjectMeta `traffic.sidecar.istio.io/includeInboundPorts`\
      \ (includeInboundPorts .Spec.Containers) ]]\"\n    - \"-d\"\n    - \"[[ excludeInboundPort\
      \ (annotation .ObjectMeta `status.sidecar.istio.io/port`  15020 ) (annotation\
      \ .ObjectMeta `traffic.sidecar.istio.io/excludeInboundPorts`  \"\" ) ]]\"\n\
      \    [[ if (isset .ObjectMeta.Annotations `traffic.sidecar.istio.io/kubevirtInterfaces`)\
      \ -]]\n    - \"-k\"\n    - \"[[ index .ObjectMeta.Annotations `traffic.sidecar.istio.io/kubevirtInterfaces`\
      \ ]]\"\n    [[ end -]]\n    imagePullPolicy: IfNotPresent\n    resources:\n\
      \      requests:\n        cpu: 10m\n        memory: 10Mi\n      limits:\n  \
      \      cpu: 100m\n        memory: 50Mi\n    securityContext:\n      runAsUser:\
      \ 0\n      runAsNonRoot: false\n      capabilities:\n        add:\n        -\
      \ NET_ADMIN\n    restartPolicy: Always\n  [[ end -]]\n  containers:\n  - name:\
      \ istio-proxy\n    image: [[ annotation .ObjectMeta `sidecar.istio.io/proxyImage`\
      \  \"docker.io/istio/proxyv2:1.1.9\"  ]]\n    ports:\n    - containerPort: 15090\n\
      \      protocol: TCP\n      name: http-envoy-prom\n    args:\n    - proxy\n\
      \    - sidecar\n    - --domain\n    - $(POD_NAMESPACE).svc.cluster.local\n \
      \   - --configPath\n    - [[ .ProxyConfig.ConfigPath ]]\n    - --binaryPath\n\
      \    - [[ .ProxyConfig.BinaryPath ]]\n    - --serviceCluster\n    [[ if ne \"\
      \" (index .ObjectMeta.Labels \"app\") -]]\n    - [[ index .ObjectMeta.Labels\
      \ \"app\" ]].$(POD_NAMESPACE)\n    [[ else -]]\n    - [[ valueOrDefault .DeploymentMeta.Name\
      \ \"istio-proxy\" ]].[[ valueOrDefault .DeploymentMeta.Namespace \"default\"\
      \ ]]\n    [[ end -]]\n    - --drainDuration\n    - [[ formatDuration .ProxyConfig.DrainDuration\
      \ ]]\n    - --parentShutdownDuration\n    - [[ formatDuration .ProxyConfig.ParentShutdownDuration\
      \ ]]\n    - --discoveryAddress\n    - [[ annotation .ObjectMeta `sidecar.istio.io/discoveryAddress`\
      \ .ProxyConfig.DiscoveryAddress ]]\n    - --zipkinAddress\n    - [[ .ProxyConfig.GetTracing.GetZipkin.GetAddress\
      \ ]]\n    - --connectTimeout\n    - [[ formatDuration .ProxyConfig.ConnectTimeout\
      \ ]]\n    - --proxyAdminPort\n    - [[ .ProxyConfig.ProxyAdminPort ]]\n    [[\
      \ if gt .ProxyConfig.Concurrency 0 -]]\n    - --concurrency\n    - [[ .ProxyConfig.Concurrency\
      \ ]]\n    [[ end -]]\n    - --controlPlaneAuthPolicy\n    - [[ annotation .ObjectMeta\
      \ `sidecar.istio.io/controlPlaneAuthPolicy` .ProxyConfig.ControlPlaneAuthPolicy\
      \ ]]\n  [[- if (ne (annotation .ObjectMeta `status.sidecar.istio.io/port`  15020\
      \ ) \"0\") ]]\n    - --statusPort\n    - [[ annotation .ObjectMeta `status.sidecar.istio.io/port`\
      \  15020  ]]\n    - --applicationPorts\n    - \"[[ annotation .ObjectMeta `readiness.status.sidecar.istio.io/applicationPorts`\
      \ (applicationPorts .Spec.Containers) ]]\"\n  [[- end ]]\n    env:\n    - name:\
      \ POD_NAME\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n\
      \    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath:\
      \ metadata.namespace\n    - name: INSTANCE_IP\n      valueFrom:\n        fieldRef:\n\
      \          fieldPath: status.podIP\n    \n    - name: ISTIO_META_POD_NAME\n\
      \      valueFrom:\n        fieldRef:\n          fieldPath: metadata.name\n \
      \   - name: ISTIO_META_CONFIG_NAMESPACE\n      valueFrom:\n        fieldRef:\n\
      \          fieldPath: metadata.namespace\n    - name: ISTIO_META_INTERCEPTION_MODE\n\
      \      value: [[ or (index .ObjectMeta.Annotations \"sidecar.istio.io/interceptionMode\"\
      ) .ProxyConfig.InterceptionMode.String ]]\n    [[ if .ObjectMeta.Annotations\
      \ ]]\n    - name: ISTIO_METAJSON_ANNOTATIONS\n      value: |\n             [[\
      \ toJSON .ObjectMeta.Annotations ]]\n    [[ end ]]\n    [[ if .ObjectMeta.Labels\
      \ ]]\n    - name: ISTIO_METAJSON_LABELS\n      value: |\n             [[ toJSON\
      \ .ObjectMeta.Labels ]]\n    [[ end ]]\n    [[- if (isset .ObjectMeta.Annotations\
      \ `sidecar.istio.io/bootstrapOverride`) ]]\n    - name: ISTIO_BOOTSTRAP_OVERRIDE\n\
      \      value: \"/etc/istio/custom-bootstrap/custom_bootstrap.json\"\n    [[-\
      \ end ]]\n    imagePullPolicy: IfNotPresent\n    [[ if (ne (annotation .ObjectMeta\
      \ `status.sidecar.istio.io/port`  15020 ) \"0\") ]]\n    readinessProbe:\n \
      \     httpGet:\n        path: /healthz/ready\n        port: [[ annotation .ObjectMeta\
      \ `status.sidecar.istio.io/port`  15020  ]]\n      initialDelaySeconds: [[ annotation\
      \ .ObjectMeta `readiness.status.sidecar.istio.io/initialDelaySeconds`  1  ]]\n\
      \      periodSeconds: [[ annotation .ObjectMeta `readiness.status.sidecar.istio.io/periodSeconds`\
      \  2  ]]\n      failureThreshold: [[ annotation .ObjectMeta `readiness.status.sidecar.istio.io/failureThreshold`\
      \  30  ]]\n    [[ end -]]securityContext:\n      readOnlyRootFilesystem: true\n\
      \      [[ if eq (annotation .ObjectMeta `sidecar.istio.io/interceptionMode`\
      \ .ProxyConfig.InterceptionMode) \"TPROXY\" -]]\n      capabilities:\n     \
      \   add:\n        - NET_ADMIN\n      runAsGroup: 1337\n      [[ else -]]\n \
      \     \n      runAsUser: 1337\n      [[- end ]]\n    resources:\n      [[ if\
      \ or (isset .ObjectMeta.Annotations `sidecar.istio.io/proxyCPU`) (isset .ObjectMeta.Annotations\
      \ `sidecar.istio.io/proxyMemory`) -]]\n      requests:\n        [[ if (isset\
      \ .ObjectMeta.Annotations `sidecar.istio.io/proxyCPU`) -]]\n        cpu: \"\
      [[ index .ObjectMeta.Annotations `sidecar.istio.io/proxyCPU` ]]\"\n        [[\
      \ end ]]\n        [[ if (isset .ObjectMeta.Annotations `sidecar.istio.io/proxyMemory`)\
      \ -]]\n        memory: \"[[ index .ObjectMeta.Annotations `sidecar.istio.io/proxyMemory`\
      \ ]]\"\n        [[ end ]]\n    [[ else -]]\n      limits:\n        cpu: 2000m\n\
      \        memory: 1024Mi\n      requests:\n        cpu: 100m\n        memory:\
      \ 128Mi\n      \n    [[ end -]]\n    volumeMounts:\n    [[- if (isset .ObjectMeta.Annotations\
      \ `sidecar.istio.io/bootstrapOverride`) ]]\n    - mountPath: /etc/istio/custom-bootstrap\n\
      \      name: custom-bootstrap-volume\n    [[- end ]]\n    - mountPath: /etc/istio/proxy\n\
      \      name: istio-envoy\n    - mountPath: /etc/certs/\n      name: istio-certs\n\
      \      readOnly: true\n      [[- if isset .ObjectMeta.Annotations `sidecar.istio.io/userVolumeMount`\
      \ ]]\n      [[ range $index, $value := fromJSON (index .ObjectMeta.Annotations\
      \ `sidecar.istio.io/userVolumeMount`) ]]\n    - name: \"[[ $index ]]\"\n   \
      \   [[ toYaml $value | indent 4 ]]\n      [[ end ]]\n      [[- end ]]\n  volumes:\n\
      \  [[- if (isset .ObjectMeta.Annotations `sidecar.istio.io/bootstrapOverride`)\
      \ ]]\n  - name: custom-bootstrap-volume\n    configMap:\n      name: [[ annotation\
      \ .ObjectMeta `sidecar.istio.io/bootstrapOverride` `` ]]\n  [[- end ]]\n  -\
      \ emptyDir:\n      medium: Memory\n    name: istio-envoy\n  - name: istio-certs\n\
      \    secret:\n      optional: true\n      [[ if eq .Spec.ServiceAccountName\
      \ \"\" -]]\n      secretName: istio.default\n      [[ else -]]\n      secretName:\
      \ [[ printf \"istio.%s\" .Spec.ServiceAccountName ]]\n      [[ end -]]\n   \
      \ [[- if isset .ObjectMeta.Annotations `sidecar.istio.io/userVolume` ]]\n  \
      \  [[ range $index, $value := fromJSON (index .ObjectMeta.Annotations `sidecar.istio.io/userVolume`)\
      \ ]]\n  - name: \"[[ $index ]]\"\n    [[ toYaml $value | indent 2 ]]\n    [[\
      \ end ]]\n    [[ end ]]"
  kind: ConfigMap
  metadata:
    labels:
      app: istio
      chart: istio
      heritage: Tiller
      istio: sidecar-injector
      kubenix/project-name: kubenix
      release: istio
    name: istio-sidecar-injector
    namespace: istio-system
- apiVersion: v1
  data:
    prometheus.yml: "global:\n  scrape_interval: 15s\nscrape_configs:\n\n- job_name:\
      \ 'istio-mesh'\n  kubernetes_sd_configs:\n  - role: endpoints\n    namespaces:\n\
      \      names:\n      - istio-system\n\n  relabel_configs:\n  - source_labels:\
      \ [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n \
      \   action: keep\n    regex: istio-telemetry;prometheus\n\n# Scrape config for\
      \ envoy stats\n- job_name: 'envoy-stats'\n  metrics_path: /stats/prometheus\n\
      \  kubernetes_sd_configs:\n  - role: pod\n\n  relabel_configs:\n  - source_labels:\
      \ [__meta_kubernetes_pod_container_port_name]\n    action: keep\n    regex:\
      \ '.*-envoy-prom'\n  - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n\
      \    action: replace\n    regex: ([^:]+)(?::\\d+)?;(\\d+)\n    replacement:\
      \ $1:15090\n    target_label: __address__\n  - action: labelmap\n    regex:\
      \ __meta_kubernetes_pod_label_(.+)\n  - source_labels: [__meta_kubernetes_namespace]\n\
      \    action: replace\n    target_label: namespace\n  - source_labels: [__meta_kubernetes_pod_name]\n\
      \    action: replace\n    target_label: pod_name\n\n  metric_relabel_configs:\n\
      \  # Exclude some of the envoy metrics that have massive cardinality\n  # This\
      \ list may need to be pruned further moving forward, as informed\n  # by performance\
      \ and scalability testing.\n  - source_labels: [ cluster_name ]\n    regex:\
      \ '(outbound|inbound|prometheus_stats).*'\n    action: drop\n  - source_labels:\
      \ [ tcp_prefix ]\n    regex: '(outbound|inbound|prometheus_stats).*'\n    action:\
      \ drop\n  - source_labels: [ listener_address ]\n    regex: '(.+)'\n    action:\
      \ drop\n  - source_labels: [ http_conn_manager_listener_prefix ]\n    regex:\
      \ '(.+)'\n    action: drop\n  - source_labels: [ http_conn_manager_prefix ]\n\
      \    regex: '(.+)'\n    action: drop\n  - source_labels: [ __name__ ]\n    regex:\
      \ 'envoy_tls.*'\n    action: drop\n  - source_labels: [ __name__ ]\n    regex:\
      \ 'envoy_tcp_downstream.*'\n    action: drop\n  - source_labels: [ __name__\
      \ ]\n    regex: 'envoy_http_(stats|admin).*'\n    action: drop\n  - source_labels:\
      \ [ __name__ ]\n    regex: 'envoy_cluster_(lb|retry|bind|internal|max|original).*'\n\
      \    action: drop\n\n- job_name: 'istio-policy'\n  kubernetes_sd_configs:\n\
      \  - role: endpoints\n    namespaces:\n      names:\n      - istio-system\n\n\
      \n  relabel_configs:\n  - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n\
      \    action: keep\n    regex: istio-policy;http-monitoring\n\n- job_name: 'istio-telemetry'\n\
      \  kubernetes_sd_configs:\n  - role: endpoints\n    namespaces:\n      names:\n\
      \      - istio-system\n\n  relabel_configs:\n  - source_labels: [__meta_kubernetes_service_name,\
      \ __meta_kubernetes_endpoint_port_name]\n    action: keep\n    regex: istio-telemetry;http-monitoring\n\
      \n- job_name: 'pilot'\n  kubernetes_sd_configs:\n  - role: endpoints\n    namespaces:\n\
      \      names:\n      - istio-system\n\n  relabel_configs:\n  - source_labels:\
      \ [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n \
      \   action: keep\n    regex: istio-pilot;http-monitoring\n\n- job_name: 'galley'\n\
      \  kubernetes_sd_configs:\n  - role: endpoints\n    namespaces:\n      names:\n\
      \      - istio-system\n\n  relabel_configs:\n  - source_labels: [__meta_kubernetes_service_name,\
      \ __meta_kubernetes_endpoint_port_name]\n    action: keep\n    regex: istio-galley;http-monitoring\n\
      \n- job_name: 'citadel'\n  kubernetes_sd_configs:\n  - role: endpoints\n   \
      \ namespaces:\n      names:\n      - istio-system\n\n  relabel_configs:\n  -\
      \ source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n\
      \    action: keep\n    regex: istio-citadel;http-monitoring\n\n# scrape config\
      \ for API servers\n- job_name: 'kubernetes-apiservers'\n  kubernetes_sd_configs:\n\
      \  - role: endpoints\n    namespaces:\n      names:\n      - default\n  scheme:\
      \ https\n  tls_config:\n    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n\
      \  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\
      \  relabel_configs:\n  - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n\
      \    action: keep\n    regex: kubernetes;https\n\n# scrape config for nodes\
      \ (kubelet)\n- job_name: 'kubernetes-nodes'\n  scheme: https\n  tls_config:\n\
      \    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n  bearer_token_file:\
      \ /var/run/secrets/kubernetes.io/serviceaccount/token\n  kubernetes_sd_configs:\n\
      \  - role: node\n  relabel_configs:\n  - action: labelmap\n    regex: __meta_kubernetes_node_label_(.+)\n\
      \  - target_label: __address__\n    replacement: kubernetes.default.svc:443\n\
      \  - source_labels: [__meta_kubernetes_node_name]\n    regex: (.+)\n    target_label:\
      \ __metrics_path__\n    replacement: /api/v1/nodes/${1}/proxy/metrics\n\n# Scrape\
      \ config for Kubelet cAdvisor.\n#\n# This is required for Kubernetes 1.7.3 and\
      \ later, where cAdvisor metrics\n# (those whose names begin with 'container_')\
      \ have been removed from the\n# Kubelet metrics endpoint.  This job scrapes\
      \ the cAdvisor endpoint to\n# retrieve those metrics.\n#\n# In Kubernetes 1.7.0-1.7.2,\
      \ these metrics are only exposed on the cAdvisor\n# HTTP endpoint; use \"replacement:\
      \ /api/v1/nodes/${1}:4194/proxy/metrics\"\n# in that case (and ensure cAdvisor's\
      \ HTTP server hasn't been disabled with\n# the --cadvisor-port=0 Kubelet flag).\n\
      #\n# This job is not necessary and should be removed in Kubernetes 1.6 and\n\
      # earlier versions, or it will cause the metrics to be scraped twice.\n- job_name:\
      \ 'kubernetes-cadvisor'\n  scheme: https\n  tls_config:\n    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n\
      \  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\
      \  kubernetes_sd_configs:\n  - role: node\n  relabel_configs:\n  - action: labelmap\n\
      \    regex: __meta_kubernetes_node_label_(.+)\n  - target_label: __address__\n\
      \    replacement: kubernetes.default.svc:443\n  - source_labels: [__meta_kubernetes_node_name]\n\
      \    regex: (.+)\n    target_label: __metrics_path__\n    replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor\n\
      \n# scrape config for service endpoints.\n- job_name: 'kubernetes-service-endpoints'\n\
      \  kubernetes_sd_configs:\n  - role: endpoints\n  relabel_configs:\n  - source_labels:\
      \ [__meta_kubernetes_service_annotation_prometheus_io_scrape]\n    action: keep\n\
      \    regex: true\n  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]\n\
      \    action: replace\n    target_label: __scheme__\n    regex: (https?)\n  -\
      \ source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]\n\
      \    action: replace\n    target_label: __metrics_path__\n    regex: (.+)\n\
      \  - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]\n\
      \    action: replace\n    target_label: __address__\n    regex: ([^:]+)(?::\\\
      d+)?;(\\d+)\n    replacement: $1:$2\n  - action: labelmap\n    regex: __meta_kubernetes_service_label_(.+)\n\
      \  - source_labels: [__meta_kubernetes_namespace]\n    action: replace\n   \
      \ target_label: kubernetes_namespace\n  - source_labels: [__meta_kubernetes_service_name]\n\
      \    action: replace\n    target_label: kubernetes_name\n\n- job_name: 'kubernetes-pods'\n\
      \  kubernetes_sd_configs:\n  - role: pod\n  relabel_configs:  # If first two\
      \ labels are present, pod should be scraped  by the istio-secure job.\n  - source_labels:\
      \ [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n    action: keep\n\
      \    regex: true\n  # Keep target if there's no sidecar or if prometheus.io/scheme\
      \ is explicitly set to \"http\"\n  - source_labels: [__meta_kubernetes_pod_annotation_sidecar_istio_io_status,\
      \ __meta_kubernetes_pod_annotation_prometheus_io_scheme]\n    action: keep\n\
      \    regex: ((;.*)|(.*;http))\n  - source_labels: [__meta_kubernetes_pod_annotation_istio_mtls]\n\
      \    action: drop\n    regex: (true)\n  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n\
      \    action: replace\n    target_label: __metrics_path__\n    regex: (.+)\n\
      \  - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n\
      \    action: replace\n    regex: ([^:]+)(?::\\d+)?;(\\d+)\n    replacement:\
      \ $1:$2\n    target_label: __address__\n  - action: labelmap\n    regex: __meta_kubernetes_pod_label_(.+)\n\
      \  - source_labels: [__meta_kubernetes_namespace]\n    action: replace\n   \
      \ target_label: namespace\n  - source_labels: [__meta_kubernetes_pod_name]\n\
      \    action: replace\n    target_label: pod_name\n\n- job_name: 'kubernetes-pods-istio-secure'\n\
      \  scheme: https\n  tls_config:\n    ca_file: /etc/istio-certs/root-cert.pem\n\
      \    cert_file: /etc/istio-certs/cert-chain.pem\n    key_file: /etc/istio-certs/key.pem\n\
      \    insecure_skip_verify: true  # prometheus does not support secure naming.\n\
      \  kubernetes_sd_configs:\n  - role: pod\n  relabel_configs:\n  - source_labels:\
      \ [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n    action: keep\n\
      \    regex: true\n  # sidecar status annotation is added by sidecar injector\
      \ and\n  # istio_workload_mtls_ability can be specifically placed on a pod to\
      \ indicate its ability to receive mtls traffic.\n  - source_labels: [__meta_kubernetes_pod_annotation_sidecar_istio_io_status,\
      \ __meta_kubernetes_pod_annotation_istio_mtls]\n    action: keep\n    regex:\
      \ (([^;]+);([^;]*))|(([^;]*);(true))\n  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]\n\
      \    action: drop\n    regex: (http)\n  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n\
      \    action: replace\n    target_label: __metrics_path__\n    regex: (.+)\n\
      \  - source_labels: [__address__]  # Only keep address that is host:port\n \
      \   action: keep    # otherwise an extra target with ':443' is added for https\
      \ scheme\n    regex: ([^:]+):(\\d+)\n  - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n\
      \    action: replace\n    regex: ([^:]+)(?::\\d+)?;(\\d+)\n    replacement:\
      \ $1:$2\n    target_label: __address__\n  - action: labelmap\n    regex: __meta_kubernetes_pod_label_(.+)\n\
      \  - source_labels: [__meta_kubernetes_namespace]\n    action: replace\n   \
      \ target_label: namespace\n  - source_labels: [__meta_kubernetes_pod_name]\n\
      \    action: replace\n    target_label: pod_name"
  kind: ConfigMap
  metadata:
    labels:
      app: prometheus
      chart: prometheus
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: prometheus
    namespace: istio-system
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: security
      chart: security
      heritage: Tiller
      istio: citadel
      kubenix/project-name: kubenix
      release: istio
    name: istio-citadel
    namespace: istio-system
  spec:
    ports:
    - name: http-monitoring
      port: 15014
    - name: grpc-citadel
      port: 8060
      protocol: TCP
      targetPort: 8060
    selector:
      istio: citadel
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: galley
      chart: galley
      heritage: Tiller
      istio: galley
      kubenix/project-name: kubenix
      release: istio
    name: istio-galley
    namespace: istio-system
  spec:
    ports:
    - name: http-monitoring
      port: 15014
    - name: https-validation
      port: 443
    - name: grpc-mcp
      port: 9901
    selector:
      istio: galley
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: istio-ingressgateway
      chart: gateways
      heritage: Tiller
      istio: ingressgateway
      kubenix/project-name: kubenix
      release: istio
    name: istio-ingressgateway
    namespace: istio-system
  spec:
    ports:
    - name: status-port
      port: 15020
      targetPort: 15020
    - name: https-kiali
      port: 15029
      targetPort: 15029
    - name: https-prometheus
      port: 15030
      targetPort: 15030
    - name: https-grafana
      port: 15031
      targetPort: 15031
    - name: https-tracing
      port: 15032
      targetPort: 15032
    - name: tls
      port: 15443
      targetPort: 15443
    - name: tcp
      nodePort: 31400
      port: 31400
    - name: https
      nodePort: 31390
      port: 443
    - name: http2
      nodePort: 31380
      port: 80
      targetPort: 80
    selector:
      app: istio-ingressgateway
      istio: ingressgateway
      release: istio
    type: LoadBalancer
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: pilot
      chart: pilot
      heritage: Tiller
      istio: pilot
      kubenix/project-name: kubenix
      release: istio
    name: istio-pilot
    namespace: istio-system
  spec:
    ports:
    - name: grpc-xds
      port: 15010
    - name: https-xds
      port: 15011
    - name: http-monitoring
      port: 15014
    - name: http-legacy-discovery
      port: 8080
    selector:
      istio: pilot
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: sidecarInjectorWebhook
      chart: sidecarInjectorWebhook
      heritage: Tiller
      istio: sidecar-injector
      kubenix/project-name: kubenix
      release: istio
    name: istio-sidecar-injector
    namespace: istio-system
  spec:
    ports:
    - port: 443
    selector:
      istio: sidecar-injector
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      networking.istio.io/exportTo: '*'
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      istio: mixer
      kubenix/project-name: kubenix
      release: istio
    name: istio-telemetry
    namespace: istio-system
  spec:
    ports:
    - name: grpc-mixer-mtls
      port: 15004
    - name: http-monitoring
      port: 15014
    - name: prometheus
      port: 42422
    - name: grpc-mixer
      port: 9091
    selector:
      istio: mixer
      istio-mixer-type: telemetry
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/scrape: 'true'
    labels:
      app: prometheus
      chart: prometheus
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: prometheus
    namespace: istio-system
  spec:
    ports:
    - name: http-prometheus
      port: 9090
      protocol: TCP
    selector:
      app: prometheus
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: virtual-services
      chart: gateways
      heritage: Tiller
      istio: virtual-services-gateway
      kubenix/project-name: kubenix
      release: istio
    name: virtual-services
    namespace: istio-system
  spec:
    ports:
    - name: argocd-port
      nodePort: 31200
      port: 15200
      targetPort: 15200
    - name: grafana-port
      nodePort: 31300
      port: 15300
      targetPort: 15300
    - name: weavescope-port
      nodePort: 31301
      port: 15301
      targetPort: 15301
    - name: zipkin-port
      nodePort: 31302
      port: 15302
      targetPort: 15302
    selector:
      app: virtual-services
      istio: virtual-services-gateway
      release: istio
    type: LoadBalancer
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      app: security
      chart: security
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-citadel-service-account
    namespace: istio-system
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      helm.sh/hook: post-delete
      helm.sh/hook-delete-policy: hook-succeeded
      helm.sh/hook-weight: '1'
    labels:
      app: security
      chart: security
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-cleanup-secrets-service-account
    namespace: istio-system
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      app: galley
      chart: galley
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-galley-service-account
    namespace: istio-system
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      app: istio-ingressgateway
      chart: gateways
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-ingressgateway-service-account
    namespace: istio-system
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-mixer-service-account
    namespace: istio-system
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      kubenix/project-name: kubenix
    name: istio-multi
    namespace: istio-system
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      app: pilot
      chart: pilot
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-pilot-service-account
    namespace: istio-system
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      app: security
      chart: security
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-security-post-install-account
    namespace: istio-system
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      app: sidecarInjectorWebhook
      chart: sidecarInjectorWebhook
      heritage: Tiller
      istio: sidecar-injector
      kubenix/project-name: kubenix
      release: istio
    name: istio-sidecar-injector-service-account
    namespace: istio-system
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      app: prometheus
      chart: prometheus
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: prometheus
    namespace: istio-system
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      app: virtual-services
      chart: gateways
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: virtual-services-service-account
    namespace: istio-system
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      app: security
      chart: security
      heritage: Tiller
      istio: citadel
      kubenix/project-name: kubenix
      release: istio
    name: istio-citadel
    namespace: istio-system
  spec:
    replicas: 1
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: 'false'
        labels:
          app: security
          chart: security
          heritage: Tiller
          istio: citadel
          release: istio
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - ppc64le
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - s390x
              weight: 2
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
                  - ppc64le
                  - s390x
        containers:
        - args:
          - --append-dns-names=true
          - --grpc-port=8060
          - --grpc-hostname=citadel
          - --citadel-storage-namespace=istio-system
          - --custom-dns-names=istio-pilot-service-account.istio-system:istio-pilot.istio-system
          - --monitoring-port=15014
          - --self-signed-ca=true
          image: docker.io/istio/citadel:1.1.9
          imagePullPolicy: IfNotPresent
          livenessProbe:
            httpGet:
              path: /version
              port: 15014
            initialDelaySeconds: 5
            periodSeconds: 5
          name: citadel
          resources:
            requests:
              cpu: 10m
        serviceAccountName: istio-citadel-service-account
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      app: galley
      chart: galley
      heritage: Tiller
      istio: galley
      kubenix/project-name: kubenix
      release: istio
    name: istio-galley
    namespace: istio-system
  spec:
    replicas: 1
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: 'false'
        labels:
          app: galley
          chart: galley
          heritage: Tiller
          istio: galley
          release: istio
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - ppc64le
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - s390x
              weight: 2
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
                  - ppc64le
                  - s390x
        containers:
        - command:
          - /usr/local/bin/galley
          - server
          - --meshConfigFile=/etc/mesh-config/mesh
          - --livenessProbeInterval=1s
          - --livenessProbePath=/healthliveness
          - --readinessProbePath=/healthready
          - --readinessProbeInterval=1s
          - --deployment-namespace=istio-system
          - --insecure=true
          - --validation-webhook-config-file
          - /etc/config/validatingwebhookconfiguration.yaml
          - --monitoringPort=15014
          - --log_output_level=default:info
          image: docker.io/istio/galley:1.1.9
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - /usr/local/bin/galley
              - probe
              - --probe-path=/healthliveness
              - --interval=10s
            initialDelaySeconds: 5
            periodSeconds: 5
          name: galley
          ports:
          - containerPort: 15014
          - containerPort: 443
          - containerPort: 9901
          readinessProbe:
            exec:
              command:
              - /usr/local/bin/galley
              - probe
              - --probe-path=/healthready
              - --interval=10s
            initialDelaySeconds: 5
            periodSeconds: 5
          resources:
            requests:
              cpu: 10m
          volumeMounts:
          - mountPath: /etc/certs
            name: certs
            readOnly: true
          - mountPath: /etc/config
            name: config
            readOnly: true
          - mountPath: /etc/mesh-config
            name: mesh-config
            readOnly: true
        serviceAccountName: istio-galley-service-account
        volumes:
        - name: certs
          secret:
            secretName: istio.istio-galley-service-account
        - configMap:
            name: istio-galley-configuration
          name: config
        - configMap:
            name: istio
          name: mesh-config
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      app: istio-ingressgateway
      chart: gateways
      heritage: Tiller
      istio: ingressgateway
      kubenix/project-name: kubenix
      release: istio
    name: istio-ingressgateway
    namespace: istio-system
  spec:
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: 'false'
        labels:
          app: istio-ingressgateway
          chart: gateways
          heritage: Tiller
          istio: ingressgateway
          release: istio
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - ppc64le
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - s390x
              weight: 2
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
                  - ppc64le
                  - s390x
        containers:
        - args:
          - proxy
          - router
          - --domain
          - $(POD_NAMESPACE).svc.cluster.local
          - --log_output_level=default:info
          - --drainDuration
          - 45s
          - --parentShutdownDuration
          - 1m0s
          - --connectTimeout
          - 10s
          - --serviceCluster
          - istio-ingressgateway
          - --zipkinAddress
          - zipkin:9411
          - --proxyAdminPort
          - '15000'
          - --statusPort
          - '15020'
          - --controlPlaneAuthPolicy
          - NONE
          - --discoveryAddress
          - istio-pilot:15010
          env:
          - name: HOST_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.hostIP
          - name: INSTANCE_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: ISTIO_META_CONFIG_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: ISTIO_META_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: ISTIO_META_ROUTER_MODE
            value: sni-dnat
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: docker.io/istio/proxyv2:1.1.9
          imagePullPolicy: IfNotPresent
          name: istio-proxy
          ports:
          - containerPort: 15020
          - containerPort: 15029
          - containerPort: 15030
          - containerPort: 15031
          - containerPort: 15032
          - containerPort: 15090
            name: http-envoy-prom
            protocol: TCP
          - containerPort: 15443
          - containerPort: 31400
          - containerPort: 443
          - containerPort: 80
          readinessProbe:
            failureThreshold: 30
            httpGet:
              path: /healthz/ready
              port: 15020
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              cpu: 2000m
              memory: 1024Mi
            requests:
              cpu: 500m
              memory: 256Mi
          volumeMounts:
          - mountPath: /etc/certs
            name: istio-certs
            readOnly: true
          - mountPath: /etc/istio/ingressgateway-ca-certs
            name: ingressgateway-ca-certs
            readOnly: true
          - mountPath: /etc/istio/ingressgateway-certs
            name: ingressgateway-certs
            readOnly: true
        serviceAccountName: istio-ingressgateway-service-account
        volumes:
        - name: ingressgateway-ca-certs
          secret:
            optional: true
            secretName: istio-ingressgateway-ca-certs
        - name: ingressgateway-certs
          secret:
            optional: true
            secretName: istio-ingressgateway-certs
        - name: istio-certs
          secret:
            optional: true
            secretName: istio.istio-ingressgateway-service-account
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    annotations:
      checksum/config-volume: f8da08b6b8c170dde721efd680270b2901e750d4aa186ebb6c22bef5b78a43f9
    labels:
      app: pilot
      chart: pilot
      heritage: Tiller
      istio: pilot
      kubenix/project-name: kubenix
      release: istio
    name: istio-pilot
    namespace: istio-system
  spec:
    selector:
      matchLabels:
        istio: pilot
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: 'false'
        labels:
          app: pilot
          chart: pilot
          heritage: Tiller
          istio: pilot
          release: istio
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - ppc64le
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - s390x
              weight: 2
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
                  - ppc64le
                  - s390x
        containers:
        - args:
          - discovery
          - --monitoringAddr=:15014
          - --log_output_level=default:info
          - --domain
          - cluster.local
          - --secureGrpcAddr
          - ''
          - --keepaliveMaxServerConnectionAge
          - 30m
          env:
          - name: GODEBUG
            value: gctrace=1
          - name: PILOT_DISABLE_XDS_MARSHALING_TO_ANY
            value: '1'
          - name: PILOT_PUSH_THROTTLE
            value: '100'
          - name: PILOT_TRACE_SAMPLING
            value: '100'
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: docker.io/istio/pilot:1.1.9
          imagePullPolicy: IfNotPresent
          name: discovery
          ports:
          - containerPort: 15010
          - containerPort: 8080
          readinessProbe:
            httpGet:
              path: /ready
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 30
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 500m
              memory: 2048Mi
          volumeMounts:
          - mountPath: /etc/certs
            name: istio-certs
            readOnly: true
          - mountPath: /etc/istio/config
            name: config-volume
        - args:
          - proxy
          - --domain
          - $(POD_NAMESPACE).svc.cluster.local
          - --serviceCluster
          - istio-pilot
          - --templateFile
          - /etc/istio/proxy/envoy_pilot.yaml.tmpl
          - --controlPlaneAuthPolicy
          - NONE
          env:
          - name: INSTANCE_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: docker.io/istio/proxyv2:1.1.9
          imagePullPolicy: IfNotPresent
          name: istio-proxy
          ports:
          - containerPort: 15003
          - containerPort: 15005
          - containerPort: 15007
          - containerPort: 15011
          resources:
            limits:
              cpu: 2000m
              memory: 1024Mi
            requests:
              cpu: 100m
              memory: 128Mi
          volumeMounts:
          - mountPath: /etc/certs
            name: istio-certs
            readOnly: true
        serviceAccountName: istio-pilot-service-account
        volumes:
        - configMap:
            name: istio
          name: config-volume
        - name: istio-certs
          secret:
            optional: true
            secretName: istio.istio-pilot-service-account
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      app: sidecarInjectorWebhook
      chart: sidecarInjectorWebhook
      heritage: Tiller
      istio: sidecar-injector
      kubenix/project-name: kubenix
      release: istio
    name: istio-sidecar-injector
    namespace: istio-system
  spec:
    replicas: 1
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: 'false'
        labels:
          app: sidecarInjectorWebhook
          chart: sidecarInjectorWebhook
          heritage: Tiller
          istio: sidecar-injector
          release: istio
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - ppc64le
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - s390x
              weight: 2
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
                  - ppc64le
                  - s390x
        containers:
        - args:
          - --caCertFile=/etc/istio/certs/root-cert.pem
          - --tlsCertFile=/etc/istio/certs/cert-chain.pem
          - --tlsKeyFile=/etc/istio/certs/key.pem
          - --injectConfig=/etc/istio/inject/config
          - --meshConfig=/etc/istio/config/mesh
          - --healthCheckInterval=2s
          - --healthCheckFile=/health
          image: docker.io/istio/sidecar_injector:1.1.9
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - /usr/local/bin/sidecar-injector
              - probe
              - --probe-path=/health
              - --interval=4s
            initialDelaySeconds: 4
            periodSeconds: 4
          name: sidecar-injector-webhook
          readinessProbe:
            exec:
              command:
              - /usr/local/bin/sidecar-injector
              - probe
              - --probe-path=/health
              - --interval=4s
            initialDelaySeconds: 4
            periodSeconds: 4
          resources:
            requests:
              cpu: 10m
          volumeMounts:
          - mountPath: /etc/istio/certs
            name: certs
            readOnly: true
          - mountPath: /etc/istio/config
            name: config-volume
            readOnly: true
          - mountPath: /etc/istio/inject
            name: inject-config
            readOnly: true
        serviceAccountName: istio-sidecar-injector-service-account
        volumes:
        - name: certs
          secret:
            secretName: istio.istio-sidecar-injector-service-account
        - configMap:
            name: istio
          name: config-volume
        - configMap:
            items:
            - key: config
              path: config
            name: istio-sidecar-injector
          name: inject-config
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      app: istio-mixer
      chart: mixer
      heritage: Tiller
      istio: mixer
      kubenix/project-name: kubenix
      release: istio
    name: istio-telemetry
    namespace: istio-system
  spec:
    selector:
      matchLabels:
        istio: mixer
        istio-mixer-type: telemetry
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: 'false'
        labels:
          app: telemetry
          chart: mixer
          heritage: Tiller
          istio: mixer
          istio-mixer-type: telemetry
          release: istio
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - ppc64le
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - s390x
              weight: 2
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
                  - ppc64le
                  - s390x
        containers:
        - args:
          - proxy
          - --domain
          - $(POD_NAMESPACE).svc.cluster.local
          - --serviceCluster
          - istio-telemetry
          - --templateFile
          - /etc/istio/proxy/envoy_telemetry.yaml.tmpl
          - --controlPlaneAuthPolicy
          - NONE
          env:
          - name: INSTANCE_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: docker.io/istio/proxyv2:1.1.9
          imagePullPolicy: IfNotPresent
          name: istio-proxy
          ports:
          - containerPort: 15004
          - containerPort: 15090
            name: http-envoy-prom
            protocol: TCP
          - containerPort: 9091
          resources:
            limits:
              cpu: 2000m
              memory: 1024Mi
            requests:
              cpu: 100m
              memory: 128Mi
          volumeMounts:
          - mountPath: /etc/certs
            name: istio-certs
            readOnly: true
          - mountPath: /sock
            name: uds-socket
        - args:
          - --monitoringPort=15014
          - --address
          - unix:///sock/mixer.socket
          - --log_output_level=default:info
          - --configStoreURL=mcp://istio-galley.istio-system.svc:9901
          - --configDefaultNamespace=istio-system
          - --useAdapterCRDs=true
          - --trace_zipkin_url=http://zipkin:9411/api/v1/spans
          - --averageLatencyThreshold
          - 100ms
          - --loadsheddingMode
          - enforce
          env:
          - name: GODEBUG
            value: gctrace=1
          - name: GOMAXPROCS
            value: '6'
          image: docker.io/istio/mixer:1.1.9
          imagePullPolicy: IfNotPresent
          livenessProbe:
            httpGet:
              path: /version
              port: 15014
            initialDelaySeconds: 5
            periodSeconds: 5
          name: mixer
          ports:
          - containerPort: 15014
          - containerPort: 42422
          resources:
            limits:
              cpu: 4800m
              memory: 4G
            requests:
              cpu: 1000m
              memory: 1G
          volumeMounts:
          - mountPath: /etc/certs
            name: istio-certs
            readOnly: true
          - mountPath: /sock
            name: uds-socket
          - mountPath: /var/run/secrets/istio.io/telemetry/adapter
            name: telemetry-adapter-secret
            readOnly: true
        serviceAccountName: istio-mixer-service-account
        volumes:
        - name: istio-certs
          secret:
            optional: true
            secretName: istio.istio-mixer-service-account
        - name: telemetry-adapter-secret
          secret:
            optional: true
            secretName: telemetry-adapter-secret
        - emptyDir: {}
          name: uds-socket
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      app: prometheus
      chart: prometheus
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: prometheus
    namespace: istio-system
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: prometheus
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: 'false'
        labels:
          app: prometheus
          chart: prometheus
          heritage: Tiller
          release: istio
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - ppc64le
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - s390x
              weight: 2
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
                  - ppc64le
                  - s390x
        containers:
        - args:
          - --storage.tsdb.retention=6h
          - --config.file=/etc/prometheus/prometheus.yml
          image: docker.io/prom/prometheus:v2.3.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
          name: prometheus
          ports:
          - containerPort: 9090
            name: http
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
          resources:
            requests:
              cpu: 10m
          volumeMounts:
          - mountPath: /etc/istio-certs
            name: istio-certs
          - mountPath: /etc/prometheus
            name: config-volume
        serviceAccountName: prometheus
        volumes:
        - configMap:
            name: prometheus
          name: config-volume
        - name: istio-certs
          secret:
            defaultMode: 420
            secretName: istio.default
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      app: virtual-services
      chart: gateways
      heritage: Tiller
      istio: virtual-services-gateway
      kubenix/project-name: kubenix
      release: istio
    name: virtual-services
    namespace: istio-system
  spec:
    replicas: 1
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: 'false'
        labels:
          app: virtual-services
          chart: gateways
          heritage: Tiller
          istio: virtual-services-gateway
          release: istio
      spec:
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - ppc64le
              weight: 2
            - preference:
                matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - s390x
              weight: 2
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: beta.kubernetes.io/arch
                  operator: In
                  values:
                  - amd64
                  - ppc64le
                  - s390x
        containers:
        - args:
          - proxy
          - router
          - --domain
          - $(POD_NAMESPACE).svc.cluster.local
          - --log_output_level=default:info
          - --drainDuration
          - 45s
          - --parentShutdownDuration
          - 1m0s
          - --connectTimeout
          - 10s
          - --serviceCluster
          - virtual-services
          - --zipkinAddress
          - zipkin:9411
          - --proxyAdminPort
          - '15000'
          - --statusPort
          - '15020'
          - --controlPlaneAuthPolicy
          - NONE
          - --discoveryAddress
          - istio-pilot:15010
          env:
          - name: HOST_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.hostIP
          - name: INSTANCE_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: ISTIO_META_CONFIG_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: ISTIO_META_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: docker.io/istio/proxyv2:1.1.9
          imagePullPolicy: IfNotPresent
          name: istio-proxy
          ports:
          - containerPort: 15090
            name: http-envoy-prom
            protocol: TCP
          - containerPort: 15200
          - containerPort: 15300
          - containerPort: 15301
          - containerPort: 15302
          readinessProbe:
            failureThreshold: 30
            httpGet:
              path: /healthz/ready
              port: 15020
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 10m
          volumeMounts:
          - mountPath: /etc/certs
            name: istio-certs
            readOnly: true
        serviceAccountName: virtual-services-service-account
        volumes:
        - name: istio-certs
          secret:
            optional: true
            secretName: istio.virtual-services-service-account
- apiVersion: policy/v1beta1
  kind: PodDisruptionBudget
  metadata:
    labels:
      app: galley
      chart: galley
      heritage: Tiller
      istio: galley
      kubenix/project-name: kubenix
      release: istio
    name: istio-galley
    namespace: istio-system
  spec:
    minAvailable: 1
    selector:
      matchLabels:
        app: galley
        istio: galley
        release: istio
- apiVersion: policy/v1beta1
  kind: PodDisruptionBudget
  metadata:
    labels:
      app: istio-ingressgateway
      chart: gateways
      heritage: Tiller
      istio: ingressgateway
      kubenix/project-name: kubenix
      release: istio
    name: istio-ingressgateway
    namespace: istio-system
  spec:
    minAvailable: 1
    selector:
      matchLabels:
        app: istio-ingressgateway
        istio: ingressgateway
        release: istio
- apiVersion: policy/v1beta1
  kind: PodDisruptionBudget
  metadata:
    labels:
      app: pilot
      chart: pilot
      heritage: Tiller
      istio: pilot
      kubenix/project-name: kubenix
      release: istio
    name: istio-pilot
    namespace: istio-system
  spec:
    minAvailable: 1
    selector:
      matchLabels:
        app: pilot
        istio: pilot
        release: istio
- apiVersion: policy/v1beta1
  kind: PodDisruptionBudget
  metadata:
    labels:
      app: telemetry
      chart: mixer
      heritage: Tiller
      istio: mixer
      istio-mixer-type: telemetry
      kubenix/project-name: kubenix
      release: istio
      version: 1.1.9
    name: istio-telemetry
    namespace: istio-system
  spec:
    minAvailable: 1
    selector:
      matchLabels:
        app: telemetry
        istio: mixer
        istio-mixer-type: telemetry
        release: istio
- apiVersion: policy/v1beta1
  kind: PodDisruptionBudget
  metadata:
    labels:
      app: virtual-services
      chart: gateways
      heritage: Tiller
      istio: virtual-services-gateway
      kubenix/project-name: kubenix
      release: istio
    name: virtual-services
    namespace: istio-system
  spec:
    minAvailable: 1
    selector:
      matchLabels:
        app: virtual-services
        istio: virtual-services-gateway
        release: istio
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      app: security
      chart: security
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-citadel-istio-system
    namespace: istio-system
  rules:
  - apiGroups:
    - ''
    resources:
    - configmaps
    verbs:
    - create
    - get
    - update
  - apiGroups:
    - ''
    resources:
    - secrets
    verbs:
    - create
    - get
    - watch
    - list
    - update
    - delete
  - apiGroups:
    - ''
    resources:
    - serviceaccounts
    - services
    verbs:
    - get
    - watch
    - list
  - apiGroups:
    - authentication.k8s.io
    resources:
    - tokenreviews
    verbs:
    - create
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    annotations:
      helm.sh/hook: post-delete
      helm.sh/hook-delete-policy: hook-succeeded
      helm.sh/hook-weight: '1'
    labels:
      app: security
      chart: security
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-cleanup-secrets-istio-system
    namespace: istio-system
  rules:
  - apiGroups:
    - ''
    resources:
    - secrets
    verbs:
    - list
    - delete
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      app: galley
      chart: galley
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-galley-istio-system
    namespace: istio-system
  rules:
  - apiGroups:
    - admissionregistration.k8s.io
    resources:
    - validatingwebhookconfigurations
    verbs:
    - '*'
  - apiGroups:
    - config.istio.io
    resources:
    - '*'
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - networking.istio.io
    resources:
    - '*'
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - authentication.istio.io
    resources:
    - '*'
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - rbac.istio.io
    resources:
    - '*'
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    - apps
    resourceNames:
    - istio-galley
    resources:
    - deployments
    verbs:
    - get
  - apiGroups:
    - ''
    resources:
    - pods
    - nodes
    - services
    - endpoints
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    resources:
    - ingresses
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    resourceNames:
    - istio-galley
    resources:
    - deployments/finalizers
    verbs:
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      app: ingressgateway
      chart: gateways
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-ingressgateway-istio-system
    namespace: istio-system
  rules:
  - apiGroups:
    - networking.istio.io
    resources:
    - virtualservices
    - destinationrules
    - gateways
    verbs:
    - get
    - watch
    - list
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-mixer-istio-system
    namespace: istio-system
  rules:
  - apiGroups:
    - config.istio.io
    resources:
    - '*'
    verbs:
    - create
    - get
    - list
    - watch
    - patch
  - apiGroups:
    - apiextensions.k8s.io
    resources:
    - customresourcedefinitions
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ''
    resources:
    - configmaps
    - endpoints
    - pods
    - services
    - namespaces
    - secrets
    - replicationcontrollers
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - extensions
    - apps
    resources:
    - replicasets
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      app: pilot
      chart: pilot
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-pilot-istio-system
    namespace: istio-system
  rules:
  - apiGroups:
    - config.istio.io
    resources:
    - '*'
    verbs:
    - '*'
  - apiGroups:
    - rbac.istio.io
    resources:
    - '*'
    verbs:
    - get
    - watch
    - list
  - apiGroups:
    - networking.istio.io
    resources:
    - '*'
    verbs:
    - '*'
  - apiGroups:
    - authentication.istio.io
    resources:
    - '*'
    verbs:
    - '*'
  - apiGroups:
    - apiextensions.k8s.io
    resources:
    - customresourcedefinitions
    verbs:
    - '*'
  - apiGroups:
    - extensions
    resources:
    - ingresses
    - ingresses/status
    verbs:
    - '*'
  - apiGroups:
    - ''
    resources:
    - configmaps
    verbs:
    - create
    - get
    - list
    - watch
    - update
  - apiGroups:
    - ''
    resources:
    - endpoints
    - pods
    - services
    - namespaces
    - nodes
    - secrets
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      kubenix/project-name: kubenix
    name: istio-reader
    namespace: istio-system
  rules:
  - apiGroups:
    - ''
    resources:
    - nodes
    - pods
    - services
    - endpoints
    - replicationcontrollers
    verbs:
    - get
    - watch
    - list
  - apiGroups:
    - extensions
    - apps
    resources:
    - replicasets
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      app: sidecarInjectorWebhook
      chart: sidecarInjectorWebhook
      heritage: Tiller
      istio: sidecar-injector
      kubenix/project-name: kubenix
      release: istio
    name: istio-sidecar-injector-istio-system
    namespace: istio-system
  rules:
  - apiGroups:
    - ''
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - admissionregistration.k8s.io
    resources:
    - mutatingwebhookconfigurations
    verbs:
    - get
    - list
    - watch
    - patch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      app: prometheus
      chart: prometheus
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: prometheus-istio-system
    namespace: istio-system
  rules:
  - apiGroups:
    - ''
    resources:
    - nodes
    - services
    - endpoints
    - pods
    - nodes/proxy
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ''
    resources:
    - configmaps
    verbs:
    - get
  - nonResourceURLs:
    - /metrics
    verbs:
    - get
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      app: virtual-services-gateway
      chart: gateways
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: virtual-services-istio-system
    namespace: istio-system
  rules:
  - apiGroups:
    - networking.istio.io
    resources:
    - virtualservices
    - destinationrules
    - gateways
    verbs:
    - get
    - watch
    - list
    - update
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      app: security
      chart: security
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-citadel-istio-system
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: istio-citadel-istio-system
  subjects:
  - kind: ServiceAccount
    name: istio-citadel-service-account
    namespace: istio-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    annotations:
      helm.sh/hook: post-delete
      helm.sh/hook-delete-policy: hook-succeeded
      helm.sh/hook-weight: '2'
    labels:
      app: security
      chart: security
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-cleanup-secrets-istio-system
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: istio-cleanup-secrets-istio-system
  subjects:
  - kind: ServiceAccount
    name: istio-cleanup-secrets-service-account
    namespace: istio-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      app: galley
      chart: galley
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-galley-admin-role-binding-istio-system
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: istio-galley-istio-system
  subjects:
  - kind: ServiceAccount
    name: istio-galley-service-account
    namespace: istio-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      app: ingressgateway
      chart: gateways
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-ingressgateway-istio-system
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: istio-ingressgateway-istio-system
  subjects:
  - kind: ServiceAccount
    name: istio-ingressgateway-service-account
    namespace: istio-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      app: mixer
      chart: mixer
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-mixer-admin-role-binding-istio-system
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: istio-mixer-istio-system
  subjects:
  - kind: ServiceAccount
    name: istio-mixer-service-account
    namespace: istio-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      chart: istio-1.1.9
      kubenix/project-name: kubenix
    name: istio-multi
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: istio-reader
  subjects:
  - kind: ServiceAccount
    name: istio-multi
    namespace: istio-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      app: pilot
      chart: pilot
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-pilot-istio-system
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: istio-pilot-istio-system
  subjects:
  - kind: ServiceAccount
    name: istio-pilot-service-account
    namespace: istio-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      app: sidecarInjectorWebhook
      chart: sidecarInjectorWebhook
      heritage: Tiller
      istio: sidecar-injector
      kubenix/project-name: kubenix
      release: istio
    name: istio-sidecar-injector-admin-role-binding-istio-system
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: istio-sidecar-injector-istio-system
  subjects:
  - kind: ServiceAccount
    name: istio-sidecar-injector-service-account
    namespace: istio-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      app: prometheus
      chart: prometheus
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: prometheus-istio-system
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus-istio-system
  subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: istio-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      app: virtual-services-gateway
      chart: gateways
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: virtual-services-istio-system
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: virtual-services-istio-system
  subjects:
  - kind: ServiceAccount
    name: virtual-services-service-account
    namespace: istio-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    labels:
      kubenix/project-name: kubenix
    name: istio-ingressgateway-sds
    namespace: istio-system
  rules:
  - apiGroups:
    - ''
    resources:
    - secrets
    verbs:
    - get
    - watch
    - list
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    labels:
      kubenix/project-name: kubenix
    name: istio-ingressgateway-sds
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: istio-ingressgateway-sds
  subjects:
  - kind: ServiceAccount
    name: istio-ingressgateway-service-account
- apiVersion: rbac.authorization.k8s.io/v1beta1
  kind: ClusterRole
  metadata:
    labels:
      app: security
      chart: security
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-security-post-install-istio-system
    namespace: istio-system
  rules:
  - apiGroups:
    - authentication.istio.io
    resources:
    - '*'
    verbs:
    - '*'
  - apiGroups:
    - networking.istio.io
    resources:
    - '*'
    verbs:
    - '*'
  - apiGroups:
    - admissionregistration.k8s.io
    resources:
    - validatingwebhookconfigurations
    verbs:
    - get
  - apiGroups:
    - extensions
    - apps
    resources:
    - deployments
    - replicasets
    verbs:
    - get
    - list
    - watch
- apiVersion: rbac.authorization.k8s.io/v1beta1
  kind: ClusterRoleBinding
  metadata:
    labels:
      app: security
      chart: security
      heritage: Tiller
      kubenix/project-name: kubenix
      release: istio
    name: istio-security-post-install-role-binding-istio-system
    namespace: istio-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: istio-security-post-install-istio-system
  subjects:
  - kind: ServiceAccount
    name: istio-security-post-install-account
    namespace: istio-system
- apiVersion: v1
  kind: Namespace
  metadata:
    labels:
      istio-injection: enabled
      serving.knative.dev/release: v0.7.1
    name: knative-serving
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      networking.knative.dev/certificate-provider: cert-manager
      serving.knative.dev/controller: 'true'
      serving.knative.dev/release: v0.7.1
    name: knative-serving-certmanager
  rules:
  - apiGroups:
    - certmanager.k8s.io
    resources:
    - certificates
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    labels:
      autoscaling.knative.dev/metric-provider: custom-metrics
      serving.knative.dev/release: v0.7.1
    name: custom-metrics-auth-reader
    namespace: kube-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: extension-apiserver-authentication-reader
  subjects:
  - kind: ServiceAccount
    name: controller
    namespace: knative-serving
- apiVersion: networking.istio.io/v1alpha3
  kind: Gateway
  metadata:
    labels:
      networking.knative.dev/ingress-provider: istio
      serving.knative.dev/release: v0.7.1
    name: knative-ingress-gateway
    namespace: knative-serving
  spec:
    selector:
      istio: ingressgateway
    servers:
    - hosts:
      - '*'
      port:
        name: http
        number: 80
        protocol: HTTP
    - hosts:
      - '*'
      port:
        name: https
        number: 443
        protocol: HTTPS
      tls:
        mode: PASSTHROUGH
- apiVersion: networking.istio.io/v1alpha3
  kind: Gateway
  metadata:
    labels:
      networking.knative.dev/ingress-provider: istio
      serving.knative.dev/release: v0.7.1
    name: cluster-local-gateway
    namespace: knative-serving
  spec:
    selector:
      istio: cluster-local-gateway
    servers:
    - hosts:
      - '*'
      port:
        name: http
        number: 80
        protocol: HTTP
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    labels:
      knative.dev/crd-install: 'true'
      serving.knative.dev/release: v0.7.1
    name: certificates.networking.internal.knative.dev
  spec:
    additionalPrinterColumns:
    - JSONPath: .status.conditions[?(@.type=="Ready")].status
      name: Ready
      type: string
    - JSONPath: .status.conditions[?(@.type=="Ready")].reason
      name: Reason
      type: string
    group: networking.internal.knative.dev
    names:
      categories:
      - all
      - knative-internal
      - networking
      kind: Certificate
      plural: certificates
      shortNames:
      - kcert
      singular: certificate
    scope: Namespaced
    subresources:
      status: {}
    version: v1alpha1
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    labels:
      knative.dev/crd-install: 'true'
      serving.knative.dev/release: v0.7.1
    name: clusteringresses.networking.internal.knative.dev
  spec:
    additionalPrinterColumns:
    - JSONPath: .status.conditions[?(@.type=='Ready')].status
      name: Ready
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].reason
      name: Reason
      type: string
    group: networking.internal.knative.dev
    names:
      categories:
      - all
      - knative-internal
      - networking
      kind: ClusterIngress
      plural: clusteringresses
      singular: clusteringress
    scope: Cluster
    subresources:
      status: {}
    version: v1alpha1
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    labels:
      knative.dev/crd-install: 'true'
    name: images.caching.internal.knative.dev
  spec:
    group: caching.internal.knative.dev
    names:
      categories:
      - all
      - knative-internal
      - caching
      kind: Image
      plural: images
      shortNames:
      - img
      singular: image
    scope: Namespaced
    subresources:
      status: {}
    version: v1alpha1
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    labels:
      knative.dev/crd-install: 'true'
      serving.knative.dev/release: v0.7.1
    name: ingresses.networking.internal.knative.dev
  spec:
    additionalPrinterColumns:
    - JSONPath: .status.conditions[?(@.type=='Ready')].status
      name: Ready
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].reason
      name: Reason
      type: string
    group: networking.internal.knative.dev
    names:
      categories:
      - all
      - knative-internal
      - networking
      kind: Ingress
      plural: ingresses
      shortNames:
      - ing
      singular: ingress
    scope: Namespaced
    subresources:
      status: {}
    version: v1alpha1
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    labels:
      knative.dev/crd-install: 'true'
      serving.knative.dev/release: v0.7.1
    name: podautoscalers.autoscaling.internal.knative.dev
  spec:
    additionalPrinterColumns:
    - JSONPath: .status.conditions[?(@.type=='Ready')].status
      name: Ready
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].reason
      name: Reason
      type: string
    group: autoscaling.internal.knative.dev
    names:
      categories:
      - all
      - knative-internal
      - autoscaling
      kind: PodAutoscaler
      plural: podautoscalers
      shortNames:
      - kpa
      singular: podautoscaler
    scope: Namespaced
    subresources:
      status: {}
    version: v1alpha1
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    labels:
      knative.dev/crd-install: 'true'
      serving.knative.dev/release: v0.7.1
    name: serverlessservices.networking.internal.knative.dev
  spec:
    additionalPrinterColumns:
    - JSONPath: .spec.mode
      name: Mode
      type: string
    - JSONPath: .status.serviceName
      name: ServiceName
      type: string
    - JSONPath: .status.privateServiceName
      name: PrivateServiceName
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].status
      name: Ready
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].reason
      name: Reason
      type: string
    group: networking.internal.knative.dev
    names:
      categories:
      - all
      - knative-internal
      - networking
      kind: ServerlessService
      plural: serverlessservices
      shortNames:
      - sks
      singular: serverlessservice
    scope: Namespaced
    subresources:
      status: {}
    version: v1alpha1
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: activator
      serving.knative.dev/release: v0.7.1
    name: activator-service
    namespace: knative-serving
  spec:
    ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 8012
    - name: http2
      port: 81
      protocol: TCP
      targetPort: 8013
    - name: metrics
      port: 9090
      protocol: TCP
      targetPort: 9090
    selector:
      app: activator
    type: ClusterIP
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      networking.knative.dev/ingress-provider: istio
      serving.knative.dev/controller: 'true'
      serving.knative.dev/release: v0.7.1
    name: knative-serving-istio
  rules:
  - apiGroups:
    - networking.istio.io
    resources:
    - virtualservices
    - gateways
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: controller
      serving.knative.dev/release: v0.7.1
    name: controller
    namespace: knative-serving
  spec:
    ports:
    - name: metrics
      port: 9090
      protocol: TCP
      targetPort: 9090
    selector:
      app: controller
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      role: webhook
      serving.knative.dev/release: v0.7.1
    name: webhook
    namespace: knative-serving
  spec:
    ports:
    - port: 443
      targetPort: 8443
    selector:
      role: webhook
- apiVersion: caching.internal.knative.dev/v1alpha1
  kind: Image
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: queue-proxy
    namespace: knative-serving
  spec:
    image: gcr.io/knative-releases/github.com/knative/serving/cmd/queue@sha256:89fb5a1d2d9c0abd10ce3135c02f9e9ffbf93087a3ece7481615a0f9d9209713
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: activator
    namespace: knative-serving
  spec:
    selector:
      matchLabels:
        app: activator
        role: activator
    template:
      metadata:
        annotations:
          cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'
          sidecar.istio.io/inject: 'true'
        labels:
          app: activator
          role: activator
          serving.knative.dev/release: v0.7.1
      spec:
        containers:
        - args:
          - -logtostderr=false
          - -stderrthreshold=FATAL
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/serving
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/activator@sha256:864c0dc5e8d8eeee6162f448ae6452ab53f53642536a4720d59b6bc2402df01f
          livenessProbe:
            httpGet:
              httpHeaders:
              - name: k-kubelet-probe
                value: activator
              path: /healthz
              port: 8012
          name: activator
          ports:
          - containerPort: 8012
            name: http1-port
          - containerPort: 8013
            name: h2c-port
          - containerPort: 9090
            name: metrics-port
          readinessProbe:
            httpGet:
              httpHeaders:
              - name: k-kubelet-probe
                value: activator
              path: /healthz
              port: 8012
          resources:
            limits:
              cpu: 200m
              memory: 600Mi
            requests:
              cpu: 20m
              memory: 60Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
          - mountPath: /etc/config-observability
            name: config-observability
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
        - configMap:
            name: config-observability
          name: config-observability
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: autoscaler
      serving.knative.dev/release: v0.7.1
    name: autoscaler
    namespace: knative-serving
  spec:
    ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: 8080
    - name: metrics
      port: 9090
      protocol: TCP
      targetPort: 9090
    - name: custom-metrics
      port: 443
      protocol: TCP
      targetPort: 8443
    selector:
      app: autoscaler
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: autoscaler
    namespace: knative-serving
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: autoscaler
    template:
      metadata:
        annotations:
          cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'
          sidecar.istio.io/inject: 'true'
        labels:
          app: autoscaler
          serving.knative.dev/release: v0.7.1
      spec:
        containers:
        - args:
          - --secure-port=8443
          - --cert-dir=/tmp
          env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/serving
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/autoscaler@sha256:026860790fe07bf3dcd42fe2c0a21c7c15ef59f4cb772b6e369f927620f6c0ec
          livenessProbe:
            httpGet:
              httpHeaders:
              - name: k-kubelet-probe
                value: autoscaler
              path: /healthz
              port: 8080
          name: autoscaler
          ports:
          - containerPort: 8080
            name: websocket
          - containerPort: 9090
            name: metrics
          - containerPort: 8443
            name: custom-metrics
          readinessProbe:
            httpGet:
              httpHeaders:
              - name: k-kubelet-probe
                value: autoscaler
              path: /healthz
              port: 8080
          resources:
            limits:
              cpu: 300m
              memory: 400Mi
            requests:
              cpu: 30m
              memory: 40Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-autoscaler
            name: config-autoscaler
          - mountPath: /etc/config-logging
            name: config-logging
          - mountPath: /etc/config-observability
            name: config-observability
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-autoscaler
          name: config-autoscaler
        - configMap:
            name: config-logging
          name: config-logging
        - configMap:
            name: config-observability
          name: config-observability
- apiVersion: v1
  data:
    _example: '################################

      #                              #

      #    EXAMPLE CONFIGURATION     #

      #                              #

      ################################


      # This block is not actually functional configuration,

      # but serves to illustrate the available configuration

      # options and document them in a way that is accessible

      # to users that `kubectl edit` this config map.

      #

      # These sample configuration options may be copied out of

      # this example block and unindented to be in the data block

      # to actually change the configuration.


      # The Revision ContainerConcurrency field specifies the maximum number

      # of requests the Container can handle at once. Container concurrency

      # target percentage is how much of that maximum to use in a stable

      # state. E.g. if a Revision specifies ContainerConcurrency of 10, then

      # the Autoscaler will try to maintain 7 concurrent connections per pod

      # on average. A value of 70 is chosen because the Autoscaler panics

      # when concurrency exceeds 2x the desired set point. So we will panic

      # before we reach the limit.

      # For legacy and backwards compatibility reasons, this value also accepts

      # fractional values in (0, 1] interval (i.e. 0.7 ⇒ 70%).

      # Thus minimal percentage value must be greater than 1.0, or it will be

      # treated as a fraction.

      # TODO(#2016): Set to 70%.

      container-concurrency-target-percentage: "100"


      # The container concurrency target default is what the Autoscaler will

      # try to maintain when the Revision specifies unlimited concurrency.

      # Even when specifying unlimited concurrency, the autoscaler will

      # horizontally scale the application based on this target concurrency.

      #

      # A value of 100 is chosen because it''s enough to allow vertical pod

      # autoscaling to tune resource requests. E.g. maintaining 1 concurrent

      # "hello world" request doesn''t consume enough resources to allow VPA

      # to achieve efficient resource usage (VPA CPU minimum is 300m).

      container-concurrency-target-default: "100"


      # When operating in a stable mode, the autoscaler operates on the

      # average concurrency over the stable window.

      stable-window: "60s"


      # When observed average concurrency during the panic window reaches

      # panic-threshold-percentage the target concurrency, the autoscaler

      # enters panic mode. When operating in panic mode, the autoscaler

      # scales on the average concurrency over the panic window which is

      # panic-window-percentage of the stable-window.

      panic-window-percentage: "10.0"


      # Absolute panic window duration.

      # Deprecated in favor of panic-window-percentage.

      # Existing revisions will continue to scale based on panic-window

      # but new revisions will default to panic-window-percentage.

      panic-window: "6s"


      # The percentage of the container concurrency target at which to

      # enter panic mode when reached within the panic window.

      panic-threshold-percentage: "200.0"


      # Max scale up rate limits the rate at which the autoscaler will

      # increase pod count. It is the maximum ratio of desired pods versus

      # observed pods.

      max-scale-up-rate: "10"


      # Scale to zero feature flag

      enable-scale-to-zero: "true"


      # Tick interval is the time between autoscaling calculations.

      tick-interval: "2s"


      # Dynamic parameters (take effect when config map is updated):


      # Scale to zero grace period is the time an inactive revision is left

      # running before it is scaled to zero (min: 30s).

      scale-to-zero-grace-period: "30s"

      '
  kind: ConfigMap
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: config-autoscaler
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: "################################\n#                              #\n\
      #    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\
      \n# This block is not actually functional configuration,\n# but serves to illustrate\
      \ the available configuration\n# options and document them in a way that is\
      \ accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample\
      \ configuration options may be copied out of\n# this block and unindented to\
      \ actually change the configuration.\n\n# IssuerRef is a reference to the issuer\
      \ for this certificate.\n# IssuerRef should be either `ClusterIssuer` or `Issuer`.\n\
      # Please refer `IssuerRef` in https://github.com/jetstack/cert-manager/blob/master/pkg/apis/certmanager/v1alpha1/types_certificate.go\n\
      # for more details about IssuerRef configuration.\nissuerRef: |\n  kind: ClusterIssuer\n\
      \  name: letsencrypt-issuer\n\n# solverConfig defines the configuration for\
      \ the ACME certificate provider.\n# The solverConfig should be either dns01\
      \ or http01.\n# Please refer `SolverConfig` in https://github.com/jetstack/cert-manager/blob/master/pkg/apis/certmanager/v1alpha1/types_certificate.go\n\
      # for more details about ACME configuration.\nsolverConfig: |\n  dns01:\n  \
      \  provider: cloud-dns-provider\n"
  kind: ConfigMap
  metadata:
    labels:
      networking.knative.dev/certificate-provider: cert-manager
      serving.knative.dev/release: v0.7.1
    name: config-certmanager
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: '################################

      #                              #

      #    EXAMPLE CONFIGURATION     #

      #                              #

      ################################


      # This block is not actually functional configuration,

      # but serves to illustrate the available configuration

      # options and document them in a way that is accessible

      # to users that `kubectl edit` this config map.

      #

      # These sample configuration options may be copied out of

      # this example block and unindented to be in the data block

      # to actually change the configuration.


      # revision-timeout-seconds contains the default number of

      # seconds to use for the revision''s per-request timeout, if

      # none is specified.

      revision-timeout-seconds: "300"  # 5 minutes


      # max-revision-timeout-seconds contains the maximum number of

      # seconds that can be used for revision-timeout-seconds.

      # This value must be greater than or equal to revision-timeout-seconds.

      # If omitted, the system default is used (600 seconds).

      max-revision-timeout-seconds: "600"  # 10 minutes


      # revision-cpu-request contains the cpu allocation to assign

      # to revisions by default.  If omitted, no value is specified

      # and the system default is used.

      revision-cpu-request: "400m"  # 0.4 of a CPU (aka 400 milli-CPU)


      # revision-memory-request contains the memory allocation to assign

      # to revisions by default.  If omitted, no value is specified

      # and the system default is used.

      revision-memory-request: "100M"  # 100 megabytes of memory


      # revision-cpu-limit contains the cpu allocation to limit

      # revisions to by default.  If omitted, no value is specified

      # and the system default is used.

      revision-cpu-limit: "1000m"  # 1 CPU (aka 1000 milli-CPU)


      # revision-memory-limit contains the memory allocation to limit

      # revisions to by default.  If omitted, no value is specified

      # and the system default is used.

      revision-memory-limit: "200M"  # 200 megabytes of memory


      # container-name-template contains a template for the default

      # container name, if none is specified.  This field supports

      # Go templating and is supplied with the ObjectMeta of the

      # enclosing Service or Configuration, so values such as

      # {{.Name}} are also valid.

      container-name-template: "user-container"

      '
  kind: ConfigMap
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: config-defaults
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: '################################

      #                              #

      #    EXAMPLE CONFIGURATION     #

      #                              #

      ################################


      # This block is not actually functional configuration,

      # but serves to illustrate the available configuration

      # options and document them in a way that is accessible

      # to users that `kubectl edit` this config map.

      #

      # These sample configuration options may be copied out of

      # this example block and unindented to be in the data block

      # to actually change the configuration.


      # List of repositories for which tag to digest resolving should be skipped

      registriesSkippingTagResolving: "ko.local,dev.local"

      '
    queueSidecarImage: gcr.io/knative-releases/github.com/knative/serving/cmd/queue@sha256:89fb5a1d2d9c0abd10ce3135c02f9e9ffbf93087a3ece7481615a0f9d9209713
  kind: ConfigMap
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: config-deployment
    namespace: knative-serving
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      autoscaling.knative.dev/metric-provider: custom-metrics
      serving.knative.dev/release: v0.7.1
    name: custom-metrics-server-resources
  rules:
  - apiGroups:
    - custom.metrics.k8s.io
    resources:
    - '*'
    verbs:
    - '*'
- apiVersion: v1
  data:
    _example: "################################\n#                              #\n\
      #    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\
      \n# This block is not actually functional configuration,\n# but serves to illustrate\
      \ the available configuration\n# options and document them in a way that is\
      \ accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample\
      \ configuration options may be copied out of\n# this example block and unindented\
      \ to be in the data block\n# to actually change the configuration.\n\n# Default\
      \ value for domain.\n# Although it will match all routes, it is the least-specific\
      \ rule so it\n# will only be used if no other domain matches.\nexample.com:\
      \ |\n\n# These are example settings of domain.\n# example.org will be used for\
      \ routes having app=nonprofit.\nexample.org: |\n  selector:\n    app: nonprofit\n\
      \n# Routes having domain suffix of 'svc.cluster.local' will not be exposed\n\
      # through Ingress. You can define your own label selector to assign that\n#\
      \ domain suffix to your Route here, or you can set the label\n#    \"serving.knative.dev/visibility=cluster-local\"\
      \n# to achieve the same effect.  This shows how to make routes having\n# the\
      \ label app=secret only exposed to the local cluster.\nsvc.cluster.local: |\n\
      \  selector:\n    app: secret\n"
  kind: ConfigMap
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: config-domain
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: '################################

      #                              #

      #    EXAMPLE CONFIGURATION     #

      #                              #

      ################################


      # This block is not actually functional configuration,

      # but serves to illustrate the available configuration

      # options and document them in a way that is accessible

      # to users that `kubectl edit` this config map.

      #

      # These sample configuration options may be copied out of

      # this example block and unindented to be in the data block

      # to actually change the configuration.


      # Delay after revision creation before considering it for GC

      stale-revision-create-delay: "24h"


      # Duration since a route has been pointed at a revision before it should be
      GC''d

      # This minus lastpinned-debounce be longer than the controller resync period
      (10 hours)

      stale-revision-timeout: "15h"


      # Minimum number of generations of revisions to keep before considering for
      GC

      stale-revision-minimum-generations: "1"


      # To avoid constant updates, we allow an existing annotation to be stale by
      this

      # amount before we update the timestamp

      stale-revision-lastpinned-debounce: "5h"

      '
  kind: ConfigMap
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: config-gc
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: '################################

      #                              #

      #    EXAMPLE CONFIGURATION     #

      #                              #

      ################################


      # This block is not actually functional configuration,

      # but serves to illustrate the available configuration

      # options and document them in a way that is accessible

      # to users that `kubectl edit` this config map.

      #

      # These sample configuration options may be copied out of

      # this example block and unindented to be in the data block

      # to actually change the configuration.


      # Default Knative Gateway after v0.3. It points to the Istio

      # standard istio-ingressgateway, instead of a custom one that we

      # used pre-0.3.

      gateway.knative-ingress-gateway: "istio-ingressgateway.istio-system.svc.cluster.local"


      # A cluster local gateway to allow pods outside of the mesh to access

      # Services and Routes not exposing through an ingress.  If the users

      # do have a service mesh setup, this isn''t required and can be removed.

      #

      # An example use case is when users want to use Istio without any

      # sidecar injection (like Knative''s istio-lean.yaml).  Since every pod

      # is outside of the service mesh in that case, a cluster-local  service

      # will need to be exposed to a cluster-local gateway to be accessible.

      local-gateway.cluster-local-gateway: "cluster-local-gateway.istio-system.svc.cluster.local"


      # To use only Istio service mesh and no cluster-local-gateway, replace

      # all local-gateway.* entries the following entry.

      local-gateway.mesh: "mesh"

      '
  kind: ConfigMap
  metadata:
    labels:
      networking.knative.dev/ingress-provider: istio
      serving.knative.dev/release: v0.7.1
    name: config-istio
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: "################################\n#                              #\n\
      #    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\
      \n# This block is not actually functional configuration,\n# but serves to illustrate\
      \ the available configuration\n# options and document them in a way that is\
      \ accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample\
      \ configuration options may be copied out of\n# this example block and unindented\
      \ to be in the data block\n# to actually change the configuration.\n\n# Common\
      \ configuration for all Knative codebase\nzap-logger-config: |\n  {\n    \"\
      level\": \"info\",\n    \"development\": false,\n    \"outputPaths\": [\"stdout\"\
      ],\n    \"errorOutputPaths\": [\"stderr\"],\n    \"encoding\": \"json\",\n \
      \   \"encoderConfig\": {\n      \"timeKey\": \"ts\",\n      \"levelKey\": \"\
      level\",\n      \"nameKey\": \"logger\",\n      \"callerKey\": \"caller\",\n\
      \      \"messageKey\": \"msg\",\n      \"stacktraceKey\": \"stacktrace\",\n\
      \      \"lineEnding\": \"\",\n      \"levelEncoder\": \"\",\n      \"timeEncoder\"\
      : \"iso8601\",\n      \"durationEncoder\": \"\",\n      \"callerEncoder\": \"\
      \"\n    }\n  }\n\n# Log level overrides\n# For all components except the autoscaler\
      \ and queue proxy,\n# changes are be picked up immediately.\n# For autoscaler\
      \ and queue proxy, changes require recreation of the pods.\nloglevel.controller:\
      \ \"info\"\nloglevel.autoscaler: \"info\"\nloglevel.queueproxy: \"info\"\nloglevel.webhook:\
      \ \"info\"\nloglevel.activator: \"info\"\n"
  kind: ConfigMap
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: config-logging
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: '################################

      #                              #

      #    EXAMPLE CONFIGURATION     #

      #                              #

      ################################


      # This block is not actually functional configuration,

      # but serves to illustrate the available configuration

      # options and document them in a way that is accessible

      # to users that `kubectl edit` this config map.

      #

      # These sample configuration options may be copied out of

      # this example block and unindented to be in the data block

      # to actually change the configuration.


      # istio.sidecar.includeOutboundIPRanges specifies the IP ranges that Istio sidecar

      # will intercept.

      #

      # Replace this with the IP ranges of your cluster (see below for some examples).

      # Separate multiple entries with a comma.

      # Example: "10.4.0.0/14,10.7.240.0/20"

      #

      # If set to "*" Istio will intercept all traffic within

      # the cluster as well as traffic that is going outside the cluster.

      # Traffic going outside the cluster will be blocked unless

      # necessary egress rules are created.

      #

      # If omitted or set to "", value of global.proxy.includeIPRanges

      # provided at Istio deployment time is used. In default Knative serving

      # deployment, global.proxy.includeIPRanges value is set to "*".

      #

      # If an invalid value is passed, "" is used instead.

      #

      # If valid set of IP address ranges are put into this value,

      # Istio will no longer intercept traffic going to IP addresses

      # outside the provided ranges and there is no need to specify

      # egress rules.

      #

      # To determine the IP ranges of your cluster:

      #   IBM Cloud Private: cat cluster/config.yaml | grep service_cluster_ip_range

      #   IBM Cloud Kubernetes Service: "172.30.0.0/16,172.20.0.0/16,10.10.10.0/24"

      #   Google Container Engine (GKE): gcloud container clusters describe XXXXXXX
      --zone=XXXXXX | grep -e clusterIpv4Cidr -e servicesIpv4Cidr

      #   Azure Kubernetes Service (AKS): "10.0.0.0/16"

      #   Azure Container Service (ACS; deprecated): "10.244.0.0/16,10.240.0.0/16"

      #   Azure Container Service Engine (ACS-Engine; OSS): Configurable, but defaults
      to "10.0.0.0/16"

      #   Minikube: "10.0.0.1/24"

      #

      # For more information, visit

      # https://istio.io/docs/tasks/traffic-management/egress/

      #

      istio.sidecar.includeOutboundIPRanges: "*"


      # clusteringress.class specifies the default cluster ingress class

      # to use when not dictated by Route annotation.

      #

      # If not specified, will use the Istio ingress.

      #

      # Note that changing the ClusterIngress class of an existing Route

      # will result in undefined behavior.  Therefore it is best to only

      # update this value during the setup of Knative, to avoid getting

      # undefined behavior.

      clusteringress.class: "istio.ingress.networking.knative.dev"


      # domainTemplate specifies the golang text template string to use

      # when constructing the Knative service''s DNS name. The default

      # value is "{{.Name}}.{{.Namespace}}.{{.Domain}}". And those three

      # values (Name, Namespace, Domain) are the only variables defined.

      #

      # Changing this value might be necessary when the extra levels in

      # the domain name generated is problematic for wildcard certificates

      # that only support a single level of domain name added to the

      # certificate''s domain. In those cases you might consider using a value

      # of "{{.Name}}-{{.Namespace}}.{{.Domain}}", or removing the Namespace

      # entirely from the template. When choosing a new value be thoughtful

      # of the potential for conflicts - for example, when users choose to use

      # characters such as `-` in their service, or namespace, names.

      # {{.Annotations}} can be used for any customization in the go template if needed.

      # We strongly recommend keeping namespace part of the template to avoid domain
      name clashes

      # Example ''{{.Name}}-{{.Namespace}}.{{ index .Annotations "sub"}}.{{.Domain}}''

      # and you have an annotation {"sub":"foo"}, then the generated template would
      be {Name}-{Namespace}.foo.{Domain}

      domainTemplate: "{{.Name}}.{{.Namespace}}.{{.Domain}}"


      # tagTemplate specifies the golang text template string to use

      # when constructing the DNS name for "tags" within the traffic blocks

      # of Routes and Configuration.  This is used in conjunction with the

      # domainTemplate above to determine the full URL for the tag.

      tagTemplate: "{{.Name}}-{{.Tag}}"


      # Controls whether TLS certificates are automatically provisioned and

      # installed in the Knative ingress to terminate external TLS connection.

      # 1. Enabled: enabling auto-TLS feature.

      # 2. Disabled: disabling auto-TLS feature.

      autoTLS: "Disabled"


      # Controls the behavior of the HTTP endpoint for the Knative ingress.

      # It requires autoTLS to be enabled.

      # 1. Enabled: The Knative ingress will be able to serve HTTP connection.

      # 2. Disabled: The Knative ingress ter will reject HTTP traffic.

      # 3. Redirected: The Knative ingress will send a 302 redirect for all

      # http connections, asking the clients to use HTTPS

      httpProtocol: "Enabled"

      '
  kind: ConfigMap
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: config-network
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: "################################\n#                              #\n\
      #    EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\
      \n# This block is not actually functional configuration,\n# but serves to illustrate\
      \ the available configuration\n# options and document them in a way that is\
      \ accessible\n# to users that `kubectl edit` this config map.\n#\n# These sample\
      \ configuration options may be copied out of\n# this example block and unindented\
      \ to be in the data block\n# to actually change the configuration.\n\n# logging.enable-var-log-collection\
      \ defaults to false.\n# The fluentd daemon set will be set up to collect /var/log\
      \ if\n# this flag is true.\nlogging.enable-var-log-collection: false\n\n# logging.revision-url-template\
      \ provides a template to use for producing the\n# logging URL that is injected\
      \ into the status of each Revision.\n# This value is what you might use the\
      \ the Knative monitoring bundle, and provides\n# access to Kibana after setting\
      \ up kubectl proxy.\nlogging.revision-url-template: |\n  http://localhost:8001/api/v1/namespaces/knative-monitoring/services/kibana-logging/proxy/app/kibana#/discover?_a=(query:(match:(kubernetes.labels.knative-dev%2FrevisionUID:(query:'${REVISION_UID}',type:phrase))))\n\
      \n# If non-empty, this enables queue proxy writing request logs to stdout.\n\
      # The value determines the shape of the request logs and it must be a valid\
      \ go text/template.\n# It is important to keep this as a single line. Multiple\
      \ lines are parsed as separate entities\n# by most collection agents and will\
      \ split the request logs into multiple records.\n#\n# The following fields and\
      \ functions are available to the template:\n#\n# Request: An http.Request (see\
      \ https://golang.org/pkg/net/http/#Request)\n# representing an HTTP request\
      \ received by the server.\n#\n# Response:\n# struct {\n#   Code    int     \
      \  // HTTP status code (see https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml)\n\
      #   Size    int       // An int representing the size of the response.\n#  \
      \ Latency float64   // A float64 representing the latency of the response in\
      \ seconds.\n# }\n#\n# Revision:\n# struct {\n#   Name          string  // Knative\
      \ revision name\n#   Namespace     string  // Knative revision namespace\n#\
      \   Service       string  // Knative service name\n#   Configuration string\
      \  // Knative configuration name\n#   PodName       string  // Name of the pod\
      \ hosting the revision\n#   PodIP         string  // IP of the pod hosting the\
      \ revision\n# }\n#\nlogging.request-log-template: '{\"httpRequest\": {\"requestMethod\"\
      : \"{{.Request.Method}}\", \"requestUrl\": \"{{js .Request.RequestURI}}\", \"\
      requestSize\": \"{{.Request.ContentLength}}\", \"status\": {{.Response.Code}},\
      \ \"responseSize\": \"{{.Response.Size}}\", \"userAgent\": \"{{js .Request.UserAgent}}\"\
      , \"remoteIp\": \"{{js .Request.RemoteAddr}}\", \"serverIp\": \"{{.Revision.PodIP}}\"\
      , \"referer\": \"{{js .Request.Referer}}\", \"latency\": \"{{.Response.Latency}}s\"\
      , \"protocol\": \"{{.Request.Proto}}\"}, \"traceId\": \"{{index .Request.Header\
      \ \"X-B3-Traceid\"}}\"}'\n\n# metrics.backend-destination field specifies the\
      \ system metrics destination.\n# It supports either prometheus (the default)\
      \ or stackdriver.\n# Note: Using stackdriver will incur additional charges\n\
      metrics.backend-destination: prometheus\n\n# metrics.request-metrics-backend-destination\
      \ specifies the request metrics\n# destination. If non-empty, it enables queue\
      \ proxy to send request metrics.\n# Currently supported values: prometheus,\
      \ stackdriver.\nmetrics.request-metrics-backend-destination: prometheus\n\n\
      # metrics.stackdriver-project-id field specifies the stackdriver project ID.\
      \ This\n# field is optional. When running on GCE, application default credentials\
      \ will be\n# used if this field is not provided.\nmetrics.stackdriver-project-id:\
      \ \"<your stackdriver project id>\"\n\n# metrics.allow-stackdriver-custom-metrics\
      \ indicates whether it is allowed to send metrics to\n# Stackdriver using \"\
      global\" resource type and custom metric type if the\n# metrics are not supported\
      \ by \"knative_revision\" resource type. Setting this\n# flag to \"true\" could\
      \ cause extra Stackdriver charge.\n# If metrics.backend-destination is not Stackdriver,\
      \ this is ignored.\nmetrics.allow-stackdriver-custom-metrics: \"false\"\n"
  kind: ConfigMap
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: config-observability
    namespace: knative-serving
- apiVersion: v1
  data:
    _example: '################################

      #                              #

      #    EXAMPLE CONFIGURATION     #

      #                              #

      ################################


      # This block is not actually functional configuration,

      # but serves to illustrate the available configuration

      # options and document them in a way that is accessible

      # to users that `kubectl edit` this config map.

      #

      # These sample configuration options may be copied out of

      # this example block and unindented to be in the data block

      # to actually change the configuration.

      #

      # If true we enable adding spans within our applications.

      enable: "false"


      # URL to zipkin collector where traces are sent.

      zipkin-endpoint: "http://zipkin.istio-system.svc.cluster.local:9411/api/v2/spans"


      # Enable zipkin debug mode. This allows all spans to be sent to the server

      # bypassing sampling.

      debug: "false"


      # Percentage (0-1) of requests to trace

      sample-rate: "0.1"

      '
  kind: ConfigMap
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: config-tracing
    namespace: knative-serving
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: controller
    namespace: knative-serving
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: controller
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: 'false'
        labels:
          app: controller
          serving.knative.dev/release: v0.7.1
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/serving
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/controller@sha256:36e48772b4a38d4790c4b72d3e05c5552b3b083709ba6bf3f355af0c4ebb216a
          name: controller
          ports:
          - containerPort: 9090
            name: metrics
          resources:
            limits:
              cpu: 1000m
              memory: 1000Mi
            requests:
              cpu: 100m
              memory: 100Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: apiregistration.k8s.io/v1beta1
  kind: APIService
  metadata:
    labels:
      autoscaling.knative.dev/metric-provider: custom-metrics
      serving.knative.dev/release: v0.7.1
    name: v1beta1.custom.metrics.k8s.io
  spec:
    group: custom.metrics.k8s.io
    groupPriorityMinimum: 100
    insecureSkipTLSVerify: true
    service:
      name: autoscaler
      namespace: knative-serving
    version: v1beta1
    versionPriority: 100
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    labels:
      networking.knative.dev/certificate-provider: cert-manager
      serving.knative.dev/release: v0.7.1
    name: networking-certmanager
    namespace: knative-serving
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: networking-certmanager
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: 'false'
        labels:
          app: networking-certmanager
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/serving
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/networking/certmanager@sha256:0868e623602dfa736092baf15c71930dff67a5eec0d89a689496525b32bdad08
          name: networking-certmanager
          ports:
          - containerPort: 9090
            name: metrics
          resources:
            limits:
              cpu: 1000m
              memory: 1000Mi
            requests:
              cpu: 100m
              memory: 100Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- aggregationRule:
    clusterRoleSelectors:
    - matchLabels:
        serving.knative.dev/controller: 'true'
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: knative-serving-admin
  rules: []
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    labels:
      networking.knative.dev/ingress-provider: istio
      serving.knative.dev/release: v0.7.1
    name: networking-istio
    namespace: knative-serving
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: networking-istio
    template:
      metadata:
        annotations:
          sidecar.istio.io/inject: 'false'
        labels:
          app: networking-istio
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          - name: CONFIG_OBSERVABILITY_NAME
            value: config-observability
          - name: METRICS_DOMAIN
            value: knative.dev/serving
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/networking/istio@sha256:5dfcc86f10638ce64c173969a685cf8d3a243cf863b62c95a952c0b4f9513f88
          name: networking-istio
          ports:
          - containerPort: 9090
            name: metrics
          resources:
            limits:
              cpu: 1000m
              memory: 1000Mi
            requests:
              cpu: 100m
              memory: 100Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: webhook
    namespace: knative-serving
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: webhook
        role: webhook
    template:
      metadata:
        annotations:
          cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'
          sidecar.istio.io/inject: 'false'
        labels:
          app: webhook
          role: webhook
          serving.knative.dev/release: v0.7.1
      spec:
        containers:
        - env:
          - name: SYSTEM_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: CONFIG_LOGGING_NAME
            value: config-logging
          image: gcr.io/knative-releases/github.com/knative/serving/cmd/webhook@sha256:76e726d1f3f015623513224c3787793f0e71294f8df9e6dca46dc92f31bec1c3
          name: webhook
          resources:
            limits:
              cpu: 200m
              memory: 200Mi
            requests:
              cpu: 20m
              memory: 20Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
          - mountPath: /etc/config-logging
            name: config-logging
        serviceAccountName: controller
        volumes:
        - configMap:
            name: config-logging
          name: config-logging
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    labels:
      knative.dev/crd-install: 'true'
      serving.knative.dev/release: v0.7.1
    name: configurations.serving.knative.dev
  spec:
    additionalPrinterColumns:
    - JSONPath: .status.latestCreatedRevisionName
      name: LatestCreated
      type: string
    - JSONPath: .status.latestReadyRevisionName
      name: LatestReady
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].status
      name: Ready
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].reason
      name: Reason
      type: string
    group: serving.knative.dev
    names:
      categories:
      - all
      - knative
      - serving
      kind: Configuration
      plural: configurations
      shortNames:
      - config
      - cfg
      singular: configuration
    scope: Namespaced
    subresources:
      status: {}
    versions:
    - name: v1alpha1
      served: true
      storage: true
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    labels:
      knative.dev/crd-install: 'true'
      serving.knative.dev/release: v0.7.1
    name: revisions.serving.knative.dev
  spec:
    additionalPrinterColumns:
    - JSONPath: .status.serviceName
      name: Service Name
      type: string
    - JSONPath: .metadata.labels['serving\.knative\.dev/configurationGeneration']
      name: Generation
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].status
      name: Ready
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].reason
      name: Reason
      type: string
    group: serving.knative.dev
    names:
      categories:
      - all
      - knative
      - serving
      kind: Revision
      plural: revisions
      shortNames:
      - rev
      singular: revision
    scope: Namespaced
    subresources:
      status: {}
    versions:
    - name: v1alpha1
      served: true
      storage: true
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    labels:
      knative.dev/crd-install: 'true'
      serving.knative.dev/release: v0.7.1
    name: routes.serving.knative.dev
  spec:
    additionalPrinterColumns:
    - JSONPath: .status.url
      name: URL
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].status
      name: Ready
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].reason
      name: Reason
      type: string
    group: serving.knative.dev
    names:
      categories:
      - all
      - knative
      - serving
      kind: Route
      plural: routes
      shortNames:
      - rt
      singular: route
    scope: Namespaced
    subresources:
      status: {}
    versions:
    - name: v1alpha1
      served: true
      storage: true
- apiVersion: apiextensions.k8s.io/v1beta1
  kind: CustomResourceDefinition
  metadata:
    labels:
      knative.dev/crd-install: 'true'
      serving.knative.dev/release: v0.7.1
    name: services.serving.knative.dev
  spec:
    additionalPrinterColumns:
    - JSONPath: .status.url
      name: URL
      type: string
    - JSONPath: .status.latestCreatedRevisionName
      name: LatestCreated
      type: string
    - JSONPath: .status.latestReadyRevisionName
      name: LatestReady
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].status
      name: Ready
      type: string
    - JSONPath: .status.conditions[?(@.type=='Ready')].reason
      name: Reason
      type: string
    group: serving.knative.dev
    names:
      categories:
      - all
      - knative
      - serving
      kind: Service
      plural: services
      shortNames:
      - kservice
      - ksvc
      singular: service
    scope: Namespaced
    subresources:
      status: {}
    versions:
    - name: v1alpha1
      served: true
      storage: true
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      serving.knative.dev/controller: 'true'
      serving.knative.dev/release: v0.7.1
    name: knative-serving-core
  rules:
  - apiGroups:
    - ''
    resources:
    - pods
    - namespaces
    - secrets
    - configmaps
    - endpoints
    - services
    - events
    - serviceaccounts
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - ''
    resources:
    - endpoints/restricted
    verbs:
    - create
  - apiGroups:
    - apps
    resources:
    - deployments
    - deployments/finalizers
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - admissionregistration.k8s.io
    resources:
    - mutatingwebhookconfigurations
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - apiextensions.k8s.io
    resources:
    - customresourcedefinitions
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - autoscaling
    resources:
    - horizontalpodautoscalers
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
  - apiGroups:
    - serving.knative.dev
    - autoscaling.internal.knative.dev
    - networking.internal.knative.dev
    resources:
    - '*'
    - '*/status'
    - '*/finalizers'
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - deletecollection
    - patch
    - watch
  - apiGroups:
    - caching.internal.knative.dev
    resources:
    - images
    verbs:
    - get
    - list
    - create
    - update
    - delete
    - patch
    - watch
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: controller
    namespace: knative-serving
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      autoscaling.knative.dev/metric-provider: custom-metrics
      serving.knative.dev/release: v0.7.1
    name: custom-metrics:system:auth-delegator
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:auth-delegator
  subjects:
  - kind: ServiceAccount
    name: controller
    namespace: knative-serving
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      autoscaling.knative.dev/metric-provider: custom-metrics
      serving.knative.dev/release: v0.7.1
    name: hpa-controller-custom-metrics
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: custom-metrics-server-resources
  subjects:
  - kind: ServiceAccount
    name: horizontal-pod-autoscaler
    namespace: kube-system
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      serving.knative.dev/release: v0.7.1
    name: knative-serving-controller-admin
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: knative-serving-admin
  subjects:
  - kind: ServiceAccount
    name: controller
    namespace: knative-serving
kind: List
labels:
